var store = [{
        "title": "[Algorithm] 1. 알고리즘과 복잡도",
        "excerpt":"알고리즘 (Algorithm) : 어떠한 문제를 해결하기 위한 절차나 방법      입력 (input) : 외부에서 제공된 자료가 존재하거나 존재하지 않아야 함   출력 (output) : 최소 1개 이상의 결과를 가져야 함   알고리즘의 복잡도 (Complexity) : 알고리즘의 성능을 나타내는 척도   공간 복잡도 (Space Complexity) : 문제를 해결할 때 걸리는 공간과 입력의 함수 관계     특정한 크기의 입력에 대해 알고리즘이 얼마나 많은 메모리를 차지하는가?   알고리즘을 위해 필요한 메모리의 양   시간 복잡도 (Time Complexity) : 문제를 해결할 때 걸리는 시간과 입력의 함수 관계     특정한 크기의 입력에 대해 알고리즘이 얼마나 오래 걸리는가?   알고리즘을 위해 필요한 연산의 횟수   만약 프로그램을 비효율적으로 작성해 시간 제한 (Time Limit)를 넘기면, 시간 초과 (Time Limit Exceeded)   빅 오 표기법 (Big-O) : 최악의 경우만을 고려해 시간 복잡도를 계산     가장 빠르게 증가할, 즉 가장 높은 차수의 항만을 고려하고 계수와 나머지 차수의 항들은 계산에서 제외   만약 크기 N의 모든 입력에 대한 알고리즘에 필요한 시간이 최대 N의 식을 가지면, 점근적 시간 복잡도는 O(N)   공통 시간 복잡도 표 (Common Time Complexity Table)   \t \t\t \t\t\t빅 오 표기법 \t\t\t설명 \t\t \t    \t                      O(1)             상수 시간                               O(logN)             로그 시간                               O(N)             선형 시간                               O(N * logN)             로그 선형 시간                               O(N^2)             2차 시간                               O(N^3)             3차 시간                               O(N^4)             4차 시간                    만약 시간 제한이 1초인 문제를 해결할 때, 시간 복잡도 …인 알고리즘을 설계해야 한다.         N의 범위가 500인 경우 : O(N^3)     N의 범위가 2,000인 경우 : O(N^2)     N의 범위가 100,000인 경우 : O(N * logN)     N의 범위가 10,000,000인 경우 : O(N^3)              수행 시간 측정 Code by Python       import time start_time = time.time() # 측정 시작 ... end_time = time.time() # 측정 종료 print(end_time - start_time) # 수행 시간 출력  ","categories": [],
        "tags": ["Algorithm"],
        "url": "/algorithm1/",
        "teaser": null
      },{
        "title": "[MacOS] 홈브류 (Homebrew)",
        "excerpt":"Homebrew : 패키지 관리 어플리케이션 (Package Management Application)      일반적으로 커맨드라인 도구나 시스템 패키지 설치에 사용   cask Package : GUI 어플리케이션 설치도 가능하게 해주는 Homebrew 확장 패키지   mas Package : App Store 어플리케이션 설치도 가능하게 해주는 Homebrew 확장 패키지   Homebrew 설치     터미널 실행 후 다음 명령어를 입력   /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"      터미널 창에 다음 명령어를 입력해 Homebrew가 정상적으로 설치되었는지 확인   brew --version // \"Homebrew X.X.X\" 출력 : 정상 설치 // \"zsh: command not found: brew\" 출력 : 설치 오류   cask Package 설치     터미널 창에 다음 명령어를 입력   brew install cask      터미널 창에 다음 명령어를 입력해 cask Package가 정상적으로 설치되었는지 확인   brew list   mas Package 설치     터미널 창에 다음 명령어를 입력   brew install mas      터미널 창에 다음 명령어를 입력해 mas Package가 정상적으로 설치되었는지 확인   brew list   Homebrew 명령어                              Homebrew 명령어 이름             Homebrew 명령어 설명                                         brew --version             Homebrew의 버전 정보 확인                               brew doctor             Homebrew 설치 환경을 검사                               brew update             Homebrew를 최신 버전으로 업데이트                               brew list             설치된 패키지를 확인                               brew upgrade             설치된 모든 패키지를 업데이트                               brew search (패키지명)             해당 패키지가 설치되어 있는지 검색                               brew install (패키지명)             해당 패키지를 최신 버전으로 설치                               brew info (패키지명)             해당 패키지의 정보 확인                               brew upgrade (패키지명)             해당 패키지를 업데이트                               brew uninstall (패키지명)             해당 패키지를 삭제                               brew outdated             최신 버전이 존재하는 패키지 확인                               brew cleanup (패키지명)             해당 패키지의 구버전에 해당하는 파일 삭제                 cask 명령어     기존의 brew 명령어 뒤에 --cask를 추가   mas 명령어                              mas 명령어 이름             mas 명령어 설명                                         mas version             mas의 버전 정보 확인                               mas list             mas로 설치된 패키지 확인                               mas upgrade             mas로 설치된 모든 패키지를 최신 버전으로 업데이트                               mas search (검색어)             앱스토어에서 해당 검색어와 일치하는 패키지 검색                               mas install (패키지 ID)             해당되는 ID를 가진 패키지를 최신 버전으로 설치                               mas upgrade (패키지 ID)             해당되는 ID를 가진 패키지를 최신 버전으로 업데이트                               mas uninstall (패키지명)             mas로 설치된 해당 패키지를 삭제                               mas outdated             mas로 설치된 패키지 중 최신 버전이 존재하는 패키지 확인                 Homebrew 삭제     터미널 실행 후 다음 명령어를 입력   // Homebrew로 설치한 모든 package를 일괄 삭제 brew remove --force --ignore-dependencies $(brew list)  // Homebrew 삭제 ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)\"      터미널 창에 다음 명령어를 입력해 Homebrew가 정상적으로 삭제되었는지 확인   brew --version // \"zsh: command not found: brew\" 출력 : 정상 삭제 // \"Homebrew X.X.X\" 출력 : 삭제 오류  ","categories": [],
        "tags": ["MacOS"],
        "url": "/homebrew1/",
        "teaser": null
      },{
        "title": "[Operation System] 1. Operation System",
        "excerpt":"운영체제 (Operation System) : 사용자가 컴퓨터에서 실행한 프로그램을 관리하고 제어      컴퓨터 시스템 자원의 효율적인 관리 (Performance) : 하드웨어 자원을 각각의 사용자 응용 프로그램에 적절히 분배            하드웨어 자원 (Hardware Resource) : CPU 시간, 기억 장치 및 디스크 영역, I/O 장치           사용자 편의성 제공 (Convenience) : 사용자가 더 편리하게 사용할 수 있는 환경을 구성       프로세스 관리 (Process Management)   메인 메모리 관리 (Main Memory Management)   파일 관리(File Management)   저장 장치 관리 (Storage Management)   I/O 장치 관리 (I/O Device Management)   시스템 호출 (System call)    부팅 (Booting) : 컴퓨터를 시작할 때 자기 자신을 구동시킬 프로그램을 스스로 불러내는 동작     메인 메모리 (Main Memory) : 즉시 필요한 데이터를 저장하는 주 기억 장치            RAM : 휘발성 주 기억 장치 (전원이 꺼지면 모든 내용이 지워짐)                    코드 영역 (Code Area) : 실행할 프로그램의 코드가 저장되는 영역                            CPU는 이 영역에 저장된 명령어를 하나씩 호출해 수행함                                   데이터 영역 (Data Area) : 실행할 프로그램의 전역 변수와 정적 변수가 저장된 영역                            프로그램 시작 시 할당, 프로그램 종료 시 소멸                                   스택 영역 (Stack Area) : 프로그램의 함수 호출과 관련된 지역 변수와 매개 변수가 정적으로 저장된 영역                            후입선출 (Last-In, First-Out) 방식에 따른 동작 : PUSH로 데이터 저장, POP로 데이터 인출               메모리의 높은 주소에서 메모리의 낮은 주소의 방향으로 할당               함수 호출 시 할당, 함수 호출 종료 시 소멸                                   힙 영역 (Heap Area) : 사용자에 의해 동적으로 할당되고 해제되는 전역 변수가 저장되는 영역                            할당되는 변수의 크기 제한이 없음 : 크기 제한이 존재하는 스택에 비해 액세스 속도가 상대적으로 느림               CPU에 의해 효율적으로 관리되는 스택 영역과 달리, 사용자가 힙 영역을 관리해야 함                                    메모리 단편화 (Memory Fragmentation) : 사용 가능한 메모리가 존재하나, 할당 불가능                                               메모리의 낮은 주소에서 메모리의 높은 주소의 방향으로 할당                                               ROM : 비휘발성 주 기억 장치 (전원이 꺼져도 그 안의 내용이 계속 유지)                    POST (Power-On Self-Test) : 부팅 시 가장 처음 실행, 현재 컴퓨터의 상태 검사           부트 로더 (Boot Loader) : POST 다음에 실행, 보조 기억 장치의 운영체제를 탐색 후 RAM에 할당                            보조 기억 장치에서 RAM으로 할당된 운영체제는 컴퓨터 전원이 꺼질 때까지 상주 (Resident)                                                   SSD/HDD : 운영체제가 저장된 보조 기억 장치            커널 (Kernel) : 운영체제가 수행하는 모든 작업이 저장       명령어 해석기 (Shell) : 사용자가 요청하는 명령어를 해석해 커널에 요청하고 결과를 출력                    응용 프로그램 (Application) : 운영체제 위에서 수행되며, 운영체제가 지원하는 자원만을 사용 가능                           일괄 처리 시스템 (Batch Processing System) : 프로그램 수행 과정의 자동화     Resident Monitor : 프로세서에 할당하기 위해 (컴파일 -&gt; 링크 -&gt; 로딩)의 과정을 하나의 프로그램으로 작성   시분할 시스템 (Time-sharing System) : CPU가 프로그램을 수행하는 시간을 제한     스위칭 (Switching) : 프로그램이 일정 시간 실행되면 Time Out을 발생시켜 다음 프로그램으로 넘어가게 함   다중 작업 (Multitasking) : CPU가 짧은 시간 내에 여러 프로그램을 스위칭해 동시에 작업하는 것처럼 보이게 함            CPU 스케줄링 (CPU Scheduling) : CPU가 어느 프로그램을 실행할지 선택하는 작업           다중 프로그래밍 (Multiprogramming) : 메모리에 여러 응용 프로그램을 적재해 idle 상태 최소화     프로그램 실행 시에 계산을 담당하는 CPU와 입출력을 담당하는 I/O 장치가 교대로 실행            idle상태 : I/O 장치가 실행되는 동안 CPU가 아무런 작업도 하지 않는 상태           인터럽트 기반 시스템 (Interrupt-based System) : 인터럽트 발생 시 ISR에 맞는 처리 수행     인터럽트 (Interrupt) : 프로그램 실행 중에 예기치 않은 상황이 발생할 경우 이를 CPU에 알리는 전기 신호            외부 인터럽트 (Eternal Interrupt) = 하드웨어 인터럽트 (Hardware Interrupt)       내부 인터럽트 (Internal Interrupt) = 소프트웨어 언터럽트 (Software Interrupt)                    예외 (Exception)           시스템 호출 (System call)                           인터럽트 서비스 루틴 (Interrupt Service Routine) : 인터럽트 신호를 처리할 방법을 내포한 운영체제 내의 코드   이중 모드 (Dual Mode Execution) : 유저 (User) 모드와 커널 (Kernel) 모드를 나눔      ! 문제 : 어떤 작업이 자원을 계속해서 점유하는 일과 같이 컴퓨터의 작업 효율을 저해하는 행위로부터 보호할 수단 필요       CPU 내 레지스터 (Register)의 Mode-Bit를 플래그 (flag)로 활용해 나타냄 (커낼 모드 : 0, 유저 모드 : 1)   각 명령어에 Mode-Bit를 넣어 시스템 내의 Mode-Bit와 같을 시에만 명령어 수행   특권 명령어 (Privileged Instruction) : 커널 모드에서만 내릴 수 있는 명령어            STOP, HALT, RESET, SET_TIMER 등       유저 모드에서는 특권 명령어를 내릴 수 없음 (내부 인터럽트를 발생해 해당 명령어를 요청한 프로그램을 강제 종료)           시스템 호출 (System Call) : Mode-Bit를 바꾸는 행위 (INT 80)            사용자가 하드웨어 자원에 접근할 때, 프로그램에서 시스템 호출을 발생시켜 운영체제에 위임해 커널 모드로 처리                   컴퓨터가 부팅되는 과정 : 커널 모드     응용 프로그램이 실행되는 과정 : 커널 모드     응용 프로그램이 실행되는 중일 때 : 유저 모드     인터럽트가 발생한 후 처리하는 과정 : 커널 모드     인터럽트를 처리한 후 : 유저 모드      하드웨어 보호 (H/W Protection) : 잘못된 명령이나 접근에 보호하기 위해 운영체제에서 내부 인터럽트 발생      ! 문제 : 정보들이 여러 I/O 장치를 통해 컴퓨터로 입출력되는 과정에서 장치 간 혹은 데이터 간의 혼선이 발생할 수 있음    입출력 장치 보호 (I/O Protection) : in, out과 같은 입출력 명령을 특권 명령으로 지정해 운영체제를 통해 수행     입출력 수행 시에는 관리자 모드로 전환해 특권 명령을 내림            Privileged Instruction Violation : 사용자가 입출력 명령을 직접 내린 경우 프로그램을 강제 종료              ! 문제 : 다른 사용자나 운영체제에 할당된 메모리 영역에 접근해 정보나 프로그램을 해킹할 수 있음    메모리 보호 (Memory Protection) : CPU와 메인 메모리 간 주소 버스에 Memory Management Unit 설치     두 개의 레지스터를 통해 해당 프로그램의 주소 범위를 저장   사용자에 할당된 메모리 영역을 벗어난 주소값을 가져오지 못하게 함   Memory Management Unit 설정은 운영체제만 변경 가능            Segment Violation : 사용자에 할당된 메모리 영역을 벗어난 주소값이 MMU에 오면 내부 인터럽트를 발생시킴              ! 문제 : 프로그램에서의 무한 루프로 인해 CPU가 독점되어 다른 프로그램이 수행되지 못할 수 있음    CPU 보호 (CPU Protection) : 타이머 (Timer)를 두어 일정 시간이 지나면 타이머 인터럽트를 발생시킴     타이머 (Timer) : 무한 루프나 자원 독점을 막기 위해 특정 시간이 지나면 타이머 인터럽트를 발생시킴            타이머 인터럽트 (Timer Interrupt) : 인터럽트의 ISR에서 CPU가 프로그램의 CPU 점유 시간을 측정해 분배       운영체제는 타이머가 끝난 작업을 종료시키고 스케줄링 (Scheduling) 이전에 타이머 실행          ","categories": [],
        "tags": ["Operation System"],
        "url": "/os1/",
        "teaser": null
      },{
        "title": "[Operation System] 2. Process",
        "excerpt":"프로세스 (Process) : 실제 메인 메모리에 할당되어 실행 중인 프로그램      프로그램은 보조 기억 장치에서 아무런 동작을 하지 않은 상태   어떤 요청에 의해 메인 메모리에 할당되어 CPU를 사용하면서 실행   각각의 프로세스는 CPU에 의해 샐행된 후 …를 생성 (메인 메모리를 효율적으로 사용해야 함)            프로세스 테이블 엔트리 = 프로세스 컨트롤 블록 (Process Control Block)       주소 공간 (Address Space)                    코드 세그먼트 (Code Segment) : 프로그램 소스 코드가 저장           데이터 세그먼트 (Data Segment) : 전역 변수가 저장           스택 세그먼트 (Stack Segment) : 지역변수와 매개변수가 저장                              지역변수와 매개변수가 후입선출을 따른 스택에 저장되므로, 전역 변수를 먼저 선언해 메인 메모리의 공간 절약 가능    프로세스의 생성과 종료 (Creation and Destruction of Process)     최초의 프로세스인 Init의 생성은 부팅된 운영체제가 처음 수행하는 작업 중 하나   생성된 프로세스가 다른 프로세스를 생성하는 과정을 반복            프로세스의 생성을 위한 시스템 호출 : fork()       프로세스의 종료를 위한 시스템 호출 : exit()           생성된 모든 프로세스는 자신을 식별할 수 있는 고유의 정수값인 PID을 가짐            생성된 모든 프로세스는 자신을 생성한 사용자 고유의 UID 값 또한 가짐 (부모와 자식이 동일한 값)                 프로세스 트리 (Process Tree) : 부모 프로세스인 A에서 자식 프로세스인 B, C, D가 파생되어 생성            부모 프로세스 : 프로세스를 생성한 프로세스       자식 프로세스 : 프로세스로부터 생성된 프로세스       형제 프로세스 : 같은 부모 프로세스에서 파생된 자식 프로세스           프로세스 컨트롤 블록 (Process Control Block) : 프로세스에 대한 모든 정보를 저장하는 곳     CPU는 여러 프로세스를 빈번히 전환하면서 수행하기에 각 프로세스의 데이터를 저장해야 작업을 이어서 수행할 수 있음   운영체제 내에서 프로세스를 관리하는 코드 부분에 저장            프로세스 컨트롤 블록에 데이터를 저장 및 복원하는 시간 역시 다중 작업을 위해 프로세스에 할당되는 시간에 포함           프로세스 상태, 프로그램 카운터, 스택 포인터, 파일 디스크립터 등의 정보 포함      프로세스 상태 (Process Status) : 각 단계들에서 상태 전이가 일어나 다음 단계로 넘어감     New : 프로그램이 메인 메모리에 할당된 상태   Ready : 프로세스가 언제든 실행 가능한 상태; 할당된 프로그램이 실행되기 위한 모든 준비를 마친 상태로 대기된 상태            n개의 작업이 있을 때, CPU의 프로세서는 스케줄러의 0~(n-1)번, 즉 n개의 작업을 번갈아 처리           Running : CPU가 해당 프로세스를 실제로 실행중인 상태   Waiting=Blocked : Running이 불가능한 상태            프로세스가 끝나지 않은 시점에 해당되는 I/O 정보가 없어 작업할 수 없음       Waiting가 끝나면 다시 CPU에 실행되기 위해 Ready로 돌아가야 함           Terminated : 프로세스가 완전히 종료된 상태              I/O 작업으로 인한 상태 변화 : Running -&gt; Waiting -&gt; Ready -&gt; Running     시간 초과로 인터럽트에 의한 상태 변화 : Running -&gt; Ready -&gt; Running      프로세스 큐 (Process Queue) : 커널이 프로세스 스케줄링을 위해 데이터 영역에서 관리하는 큐     Ready Queue : 프로세스 상태가 Ready인 프로세스들이 CPU 제어를 기다리는 큐            어떤 CPU 스케줄링 알고리즘을 선택하는지에 따라 CPU 제어 순서가 달라짐           Job Queue : 보조 기억 장치의 프로그램이 실행되기 위해 메인 메모리의 할당 순서를 기다리는 큐            시스템 내의 모든 프로세스 관리 : Ready Queue, Device Queue에 속한 모든 프로세스 포함           Device Queue : 프로세스 상태가 Waiting인 프로세스들이 CPU 외의 자원을 기다리는 큐            기다리는 자원들마다 큐가 할당되며, 해당 자원이 사용되면 인터럽트를 발생시키고 Ready Queue로 이동                 각 큐는 프로세스의 프로세스 컨트롤 블록을 가리키는 포인터 방식으로 연결 리스트를 구현   스케줄러 (CPU Scheduler) : 프로세스 순서를 정해 프로세스 큐에 올릴 것을 결정하는 커널의 코드     장기 스케줄러 (Long-term Scheduler) : 생성된 프로세스 중 Job Queue에서 Ready Queue에 이동시킬 것 선택            장기 스케줄러는 현재 메모리에 할당된 프로세스의 개수 (Degree of multiprogramming)를 제어       장기 스케줄러는 I/O bound Process,CPU bound Process를 메인 메모리에 적절히 할당해야 함                    I/O bound Process : I/O 작업 (입출력) 비중이 높은 프로세스           CPU bound Process : CPU 작업 (계산) 비중이 높은 프로세스                           중기 스케줄러 (Medium-term Scheduler) : 실행 중인 프로세스 중 보조 저장 장치로 옮길 것을 주기적으로 검사            Swapping (Swap-out↔Swap-in) : Swap-in할 때 이전 공간으로 재할당되는 것은 보장되지 않음                    Swap-out : 메인 메모리에서 우선 순위가 은 프로세스를 통째로 보조 기억 장치로 저장           Swap-in : 나중에 해당 프로세스가 다시 사용되려 할 때 보조 기억 장치에서 메인 메모리에 다시 할당                       중기 스케줄러 또한 현재 메모리에 할당된 프로세스의 개수 (Degree of multiprogramming)를 제어           단기 스케줄러 (Short-term Scheduler) : Ready Queue 내에서 프로세스들 중 어떤 것을 다음에 실행시킬지 선택            CPU 스케줄러 (CPU Scheduler) 라고도 부르며, 시분할 시스템에서 Time Out이 발생하면 호출           문맥 전환 (Context Switching) : CPU가 실행중인 프로세스를 멈추고 다른 프로세스를 실행하는 작업     문맥 (Context) : 각 프로세스 컨트롤 블록 내에서 표현            하드웨어 문맥 : 프로그램 카운터 정보와 레지스터 정보를 저장       프로세스 주소 공간 : 각 프로세스가 갖고 있는 독자적인 주소 공간에 위치           CPU 스케줄러 : CPU가 어느 프로세스를 다음에 실행할지 지정   디스패쳐 (Dispatcher) : 문맥 전환이 발생하면 Ready에서 Running으로 상태 전이            문맥 전환 오버헤드 (Context Switching Overhead) : 문맥 전환이 발생할 때마다 디스패쳐를 매번 실행시킴                CPU에서 실행중인 프로세스의 데이터는 해당 프로세스의 프로세스 컨트롤 블록에 갱신   새로 시작될 프로세스의 프로세스 컨트롤 블록를 CPU로 복원   캐시와 Translation Lookup Buffer를 재설정           시스템 호출로 인한 인터럽트 발생 시 :                실행 중인 프로세스의 문맥을 프로세스 컨트롤 블록에 갱신하나, 문맥 전환은 이루어지지 않음                 ","categories": [],
        "tags": ["Operation System"],
        "url": "/os2/",
        "teaser": null
      },{
        "title": "[Operation System] 3. CPU Scheduling",
        "excerpt":"CPU 스케줄링 (CPU Scheduling) : CPU 스케줄러에서 어느 프로세스를 다음에 실행할지 지정      선점 (Preemptive) : 한 프로세스가 CPU를 점유하는 동안, 다른 프로세스가 CPU를 강제로 점유할 수 있음   비선점 (Non-Preemptive) : 한 프로세스가 CPU를 점유하는 동안, 다른 프로세스가 CPU를 점유할 수 없음            예외 : I/O 발생           CPU 스케줄링 척도 (CPU Scheduling Criteria) : CPU 스케줄링의 효율을 분석하는 기준     CPU 점유율 (CPU Utilization) : 현재 CPU가 작업을 수행하는 비율 -&gt; 높을수록 좋음   처리율 (Throughput) : 단위 시간 당 완료되는 프로세스의 개수 -&gt; 많을수록 좋음   소요 시간 (Turnaround Time) : 프로세스가 생성된 시간부터 종료되는 데까지 걸린 시간 -&gt; 짧을수록 좋음   대기 시간 (Waiting Time) : CPU 제어를 위해 Ready Queue에서”만” 대기한 시간 -&gt; 짧을수록 좋음            평균 대기 시간 (Average Waiting Time) : (각 프로세스들의 대기 시간의 합) / (프로세스들의 개수)           응답 시간 (Response Time) : Interactive System에서 입력에 대한 반응 시간 -&gt; 짧을수록 좋음   선입선출 (First-Come, First-Served) 스케줄링 : 가장 먼저 작업을 요청한 프로세스를 먼저 수행     비선점 (Non-Preemptive)   들어온 순서대로 작업을 수행한다고 해도 그것이 반드시 효율적이지 않음            Convoy Effect : CPU를 많이 점유하는 프로세스가 먼저 수행되어 나머지 프로세스들이 그만큼 오래 대기                \t \t\t \t\t\tProcess \t\t\tBurst Time (msec) \t\t \t    \t                P1         3                       P2         3                       P3         24                     FCFS Scheduling : (CPU에 요청받은 순서대로) P1, P2, P3 순으로 처리한다.                Average Waiting Time : (0 + 3 + 6) / 3 = 3msec                       \t \t\t \t\t\tProcess \t\t\tBurst Time (msec) \t\t \t    \t                P1         24                       P2         3                       P3         3                     FCFS Scheduling : (CPU에 요청받은 순서대로) P1, P2, P3 순으로 처리한다.                Average Waiting Time : (0 + 24 + 27) / 3 = 17msec                 CPU를 오래 점유하는 P3로 상대적으로 빠른 처리가 가능한 P1과 2가 오래 대기하는 Convoy Effect 발생!      최단작업 (Shortest-Job-First) 스케줄링 : 시간이 가장 짧게 수행되는 프로세스를 먼저 수행     비선점 (Non-Preemptive), 선점 (Preemptive)   일반적으로 가장 빠른 평균 대기 시간을 가지나, 현실에선 각 프로세스의 CPU 점유 시간이 주어지지 않아 비현실적        \t \t\t \t\t\tProcess \t\t\tBurst Time (msec) \t\t \t    \t                P1         6                       P2         8                       P3         7                       P4         3                     FCFS Scheduling : (CPU에 요청받은 순서대로) P1, P2, P3, P4 순으로 처리한다.                Average Waiting Time : (0 + 6 + 14 + 21) / 4 = 10.25msec                 SJF Scheduling : (작업 시간이 짧은 순서대로) P4, P1, P3, P2 순으로 처리한다.                Average Waiting Time : (0 + 3 + 9 + 16) / 4 = 7msec                  우선순위 (Priority) 스케줄링 : 우선순위가 가장 높은 프로세스를 먼저 수행     비선점 (Non-Preemptive), 선점 (Preemptive)   우선순위는 정수값으로 표현되며, 값이 작을수록 우선순위가 높음        \t \t\t \t\t\tProcess \t\t\tBurst Time (msec)       Priority \t\t \t    \t                P1         10         3                       P2         1         1                       P3         2         4                       P4         1         5                       P5         5         2                     Priority Scheduling : (우선순위가 높은 순서대로) P2, P5, P1, P3, P4 순으로 처리한다.                Average Waiting Time : (0 + 1 + 6 + 16 + 18) / 5 = 8.2 msec                  라운드 로빈 (Round-Robin) 스케줄링 : 원 모양으로 모든 프로세스를 돌아가면서 수행     선점 (Preemptive)   시분할 시스템에서 CPU가 한 프로세스를 일정 시간 수행한 뒤 대기 상태로 보내고, 다음 프로세스를 수행하는 것 반복            Time Quantum : CPU가 한 프로세스를 수행하는 시간 -&gt; 스케줄리의 효율성이 Time Quantum의 크기에 의존                \t \t\t \t\t\tProcess \t\t\tBurst Time (msec)       Time Quantum \t\t \t    \t                P1         7         4msec                       P2         4                       P3         4                     RP Scheduling : (CPU에 요청받은 순서) P1, P2, P3, 그리고 (완료하지 못한) P1 순으로 처리                Average Waiting Time : (4 + 8 + 12) / 3 = 8 msec                       \t \t\t \t\t\tProcess \t\t\tBurst Time (msec)       Time Quantum \t\t \t    \t                P1         7         3msec                       P2         4                       P3         4                     RP Scheduling : (CPU에 요청받은 순서) P1, P2, P3, (완료하지 못한) P1, P2, P3, 그리고 P1 순으로 처리                Average Waiting Time : (12 + 13 + 14) / 3 = 13 msec                  멀티레벨 큐 (Multi-level Queue) 스케줄링 : 각 프로세스 그룹에 따른 큐를 두어 수행     프로세스 그룹 : 프로세스를 기준에 따라 여러 그룹으로 나누고, 각 그룹에 따른 큐 배치            Interactive Process : 유저 수준 &gt; 데이터를 바로바로 처리 (I/O bound Process)       Batch Process : 유저 수준 &gt; 일정 시간에 데이터를 한번에 처리 (CPU bound Process)           우선순위에 따라 대기할 큐를 지정할 수 있고, 각 큐마다 서로 다른 스케줄링 방식을 사용 가능   멀티레벨 피드백 큐 (Multi-level Feedback Queue) 스케줄링 : 멀테레벨 큐에 피드백 추가     멀티레벨 큐처럼 프로세스를 여러 그룹으로 나누고, 각 그룹에 따른 큐 배치            모든 프로세스들은 처음에는 무조건 우선순위가 가장 높은 큐에서 대기                    vs 멀티레벨 큐 : 우선순위에 따른 큐 지정 가능                           피드백 (Feedback) : time out이 발생한 프로세스를 보다 낮은 우선순위의 큐로 격하            I/O bound Process는 높은 우선순위, CPU bound Process는 낮은 우선순위          ","categories": [],
        "tags": ["Operation System"],
        "url": "/os3/",
        "teaser": null
      },{
        "title": "[Operation System] 4. IPC",
        "excerpt":"프로세스 간 통신 (Inter Process Communication) : 프로세스 간에 데이터를 주고받는 행위      독립 프로세스 (Independent Process) : (단일 처리 시스템에서) 다른 프로세스에 독립적인 동기적 프로세스   협력 프로세스 (Cooperating Process) : 실행중인 다른 프로세스와의 상호 작용을 통해 수행되는 비동기적 프로세스   공유 메모리 (Shared Memory) : 협력 프로세스 간 하나의 공유 메모리 영역을 만들어 상호 통신     공유 메모리 세그먼트 : 공유 메모리 영역은 공유 메모리 세그먼트를 생성하는 프로세스의 주소 공간에 위치       커널 의존성이 낮아 속도가 빠르고, 유저 레벨에서의 IPC가 가능해 자유로운 통신이 가능   대량의 정보를 다수의 프로세스에게 배포 가능함   자원과 데이터를 공유하므로, 동기화 문제가 발생할 수 있음   메시지 패싱 (Message Passing) : 협력 프로세스 간 각자의 메시지를 운영 체제에 전달해 통신     별도의 구축 없이 커널만을 이용하기에 비교적 구현이 쉬움   커널을 이용할 때마다, 시스템 호출에 따른 문맥 전환이 매번 발생 (문맥 복사 2번 수행, 문맥 전환 오버헤드 발생)   파이프 (PIPE) : 통신을 위한 버퍼를 생성해 프로세스가 데이터를 상호 통신          익명 파이프 (Anonymous PIPE) : 통신할 프로세스를 명확히 아는 경우             부모-자식 혹은 형제 간 통신에 사용 (외부 프로세스에서 사용할 수 없음)       하나의 프로세스는 데이터를 쓰기만, 다른 하나는 데이터를 읽기만 수행 → 반 이중 (Half-Duplex) 통신       송수신을 모두 하기 원한다면 파이프를 2개 구현해야 함                네임드 파이프 (Named PIPE) : 전혀 모르는 상태의 프로세스 간의 통신에 사용             익명 파이프의 확장된 상태 : FIFO를 통해 이름이 있는 파일을 사용하여 프로세스 간 통신       송수신을 모두 하기 원한다면 파이프를 2개 구현해야 함           소켓 (Socket) : 동일한 운영체제에서 실행되는 프로세스 간 데이터를 교환하는 Endpoint     클라이어트와 서버가 네트워크 소켓 통신을 통해 데이터를 공유 (원격에서 프로세스 간 데이터를 공유할 때 사용)            양쪽 PC에서 각각 임의의 포트를 정하고 해당 포트 간의 대화를 통해 데이터를 주고받음       각각의 PC의 포트를 담당하는 소켓은 데이터를 송수신하는 역할을 맡은 하나의 프로세스           전이중 (Full Duplex) 통신이 가능 : 서버-클라이언트 환경을 구축하는 데에 용이   중대형 어플리케이션에서 주로 사용   메시지 큐 (Message Queue) : 메모리 공간을 활용한 PIPE     입출력 방식은 Named PIPE와 유사   PIPE나 FIFO와 달리 다수의 프로세스 간 메시지를 전달할 수 있음   사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 다룰 수 있음 → 메시지 접근을 위한 키 (Key) 필요   메모리 맵 (Memory Map) : 열린 파일을 메모리에 맵핑시켜서 공유     공유 메모리처럼 메모리를 공유함 (공유 매개체가 파일 + 메모리)   주로 파일로 대용량 데이터를 공유해야 할 때 사용, 파일 입출력이 느릴 때 사용하면 편리   대부분의 운영체제에서 프로세스를 실행할 때 실행 파일의 각 세그먼트를 메모리에 사상하기 위해 메모리 맵 파일 사용   메모리 맵 파일은 파일 크기를 변경할 수 없으며, 메모리 맵 파일을 사용하기 이전 혹은 이후에만 파일 크기를 변경 가능  ","categories": [],
        "tags": ["Operation System"],
        "url": "/os4/",
        "teaser": null
      },{
        "title": "[Operation System] 5. Thread",
        "excerpt":"쓰레드 (Thread) : 프로세스 내부의 흐름      CPU를 구성하는 기본 단위로, 일반적으로 하나의 프로세스는 하나의 쓰레드가 존재   하나의 쓰레드는 고유한 Thread ID, Program Counter, Register Set 및 Stack을 가짐   다중 쓰레드 (Multi-Threads) :  하나의 프로세스에 쓰레드가 2개 이상 존재     Concurrent : 한 프로세스에서 여러 쓰레드가 빠른 시간 간격으로 스위칭되어 동시에 실행되는 것처럼 보임            여러 쓰레드들이 하나의 프로세스 안에 속하면서 code, data 메모리 공간과 프로세스 자원 file과 I/O 공유       메시지 패싱 X (운영 체제를 거치지 않고도 통신 가능), 공유 메모리 X (공유 메모리를 만들지 않아도 됨)                    멀티 프로세스에 비해 문맥 전환 시간이 짧고, 메모리와 자원의 할당이 더 효율적                           운영체제가 다중 쓰레드를 지원 : 현대 운영체제에서의 문맥 전환은 프로세스가 아닌 쓰레드 단위로 이루어짐            하나의 프로세스 안에서 여러 쓰레드가 수행되다가 다른 프로세스로 넘어가 그 프로세스의 쓰레드를 수행함                    웹 브라우저 : 화면을 출력하는 쓰레드와 데이터를 읽어오는 쓰레드가 따로 수행                              프로세스와 쓰레드의 비교 : 다중 프로세스와 다중 쓰레드는 둘다 여러 흐름이 동시에 진행된다는 공통점을 가지나,          다중 프로세스에서 각 프로세스는 독립적으로 실행되며 각각 별개의 메모리를 차지한다.     다중 쓰레드는 프로세스 내 메모리를 공유해 사용할 수 있다. 고로, 프로세스보다 스레드 간의 전환 속도가 빠르다.     다중 쓰레드는 CPU가 여러 개일 경우에 각 CPU가 스레드 하나씩을 담당하는 방법으로 속도를 높일 수 있다.     다중 쓰레드는 각각의 쓰레드 중 어떤 것이 먼저 실행될지 그 순서를 알 수 없어 ‘경쟁 조건’의 문제가 발생한다.      다중 쓰레드 모델 (Multi-Threads Models) :  2개 이상의 쓰레드로 구성된 모델     유저 쓰레드 (User Thread) : 유저 레벨의 쓰레드 라이브러리를 통해 관리되는 쓰레드   커널 쓰레드 (Kernel Thread) :  운영체제가 제공하고 직접 관리하는 쓰레드   Many-to-One 모델 : 한 커널 쓰레드가 여러 유저 쓰레드 처리     병목 현상 : 시스템 호출이 발생하면, 모든 유저 쓰레드가 대기해야 함   One-to-One 모델 : 유저 쓰레드 한 개당 커널 쓰레드를 대응시켜 처리     커널 쓰레드가 과도하게 생성되어 비효율적임   Many-to-Many 모델 : 여러 유저 쓰레드가 여러 커널 쓰레드 처리     커널 쓰레드의 수는 유저 쓰레드의 수보다 작거나 같게 해야 함   Two-Level 모델 : 중요한 작업은 One-to-One으로, 나머지는 Many-to-One으로 처리  ","categories": [],
        "tags": ["Operation System"],
        "url": "/os5/",
        "teaser": null
      },{
        "title": "[Operation System] 6. Main Memory Management",
        "excerpt":"메인 메모리 관리 (Main Memory Management)      메모리 공간은 기본적으로 주소 (address)와 데이터 (data)로 구성되어 있음            CPU는 주소를 가지고 메인 메모리에 요청을 하거나 해당 주소에 계산 결과를 저장       메인 메모리는 CPU가 요구하는 주소에 저장되어 있는 데이터를 CPU에게 전달                 프로그램의 빌드는 소스 파일, 목적 파일, 실행 파일 순서로 생성            소스 파일 (Source file) : 고수준 언어 또는 어셈블리어                    컴파일 단계 : 소스 파일은 컴파일러 또는 어셈블러에 의해 컴파일 또는 어셈블하여 목적 파일 생성                       목적 파일 (Object file) : 컴파일된 결과 또는 어셈블된 결과                    링크 단계 : 목적 파일은 링커 (Linker)에 의해 라이브러리를 찾아 정보를 추가해 실행 파일 생성                       실행 파일 (Executable file) : 링크된 결과                    로드 단계 : 실행 파일은 로더 (Loader)에 의해 메인 메모리에 할당                                 빌드된 프로그램은 code, data, stack 영역으로 구분됨            단순히 생성된 프로그램은 code, data 영역만 존재       로드 단계에서 프로그램이 실행을 위해 메모리에 적재되었을 때, 운영체제에 의해 stack 영역이 추가됨           메모리 계층 (Memory hierarchy) : 각각의 특징이 있는 저장 장치를 혼용해 효율성 극대화     메모리 매니저 (Memory Manager) : 메모리 하이라키를 관리하는 관리 시스템의 일부분         캐시 (Cash) : 빠르고, 비싸고, 휘발성   메인 메모리 (Main Memory) : 캐시보다 느리고, 캐시보다 싸고, 휘발성   디스크 스토리지 (Disk Storage) : 메인 메모리보다 느리고, 메인 메모리보다 싸고, 비휘발성      메모리 계층 구조를 통해 프로그래머가 사용하기 좋은 모델로 추상화하고, 운영체제를 통해 추상회된 객체를 관리한다.    Q. CPU가 한 번에 한 프로세스를 수행하면? : Mono-Programming      메인 프레임 (mainframe) : RAM 위의 OS에 유저 프로그램이 주소로 연결되어 존재   임베디드 시스템 (Embedded System) : OS가 위치한 ROM 아래에 유저 프로그램이 주소로 연결되어 존재   퍼스널 컴퓨터 (personal computer) : 메인 프레임 + ROM 위 장치 관리자가 유저 프로그램 위에서 OS의 관리를 받음      하단 내용은, CPU가 여러 프로세스를 돌아가면서 수행하는 Multi-Programming 환경이라 가정한다.    Q. 만약 메모리 추상화를 사용하지 않는다면? : 모든 프로그램이 물리 메모리를 직접 사용     프로그래머에게 제공되는 메모리 영역 : 실제 물리 메모리 (0 ~ (실제 물리 메모리의 크기))            각 주소는 n비트로 구성된 셀 (Cell)로 정의           하드웨어의 도움 없이 두 프로그램이 동시에 메모리에서 실행된다는 것은 불가능            메모리의 프로세스를 이미지 형태로 디스크에 저장하고, 프로그램을 메모리로 스와핑 (Swapping)할 순 있음              ! 메모리 추상화를 사용하지 않는다고 했으니, 메모리 계층 구조 또한 존재하지 않는거네?         아니다. 메모리를 추상화하는 방법 중 하나로, 메모리 추상화를 사용하지 않는 것이다.                { a, b, c, d, … } 를 추상화하는 방법 (1) := alphabetic         { a, b, c, d, … } 를 추상화하는 방법 (2) := { a, b, c, d, … }                   … 운영체제는 메모리 계층 구조를 이루는 캐시, 메인 메모리, 디스크 스토리지를 물리 주소를 통해 직접 접근한다.         그런데, 물리 주소를 직접 접근하는 방법에는 Protection &amp; Relocation 이슈가 존재한다.      P1. 프로텍션 (Protection) : 한 프로세스가 운영체제나 다른 프로세스의 파티션을 침범하지 못하게 해야 함     IBM360모델 : 프로텍션 코드 (Protection code)            프로세스의 PSW에는 4bit 키가 포함 / 메모리를 2KB 블럭 단위로 나누고, 각 블록에 4bit 프로텍션 코드 할당       수행되는 프로세스는 자신의 PSW 키와 액세스하는 블럭의 프로텍션 코드를 비교해, 일치하지 않으면 트랩 발생           P2. 리로케이트 (Relocation) : 변수 주소나 프로시저 주소에 대한 접근에 차이가 발생     컴파일된 .exe 파일을 파티션에 로드해 실행할 때, 바이너리 파일이 아닌, 파티션을 기준으로 접근해야 함            컴파일된 .exe 파일을 파티션 A와 B에 각각 로드해 실행할 때, 각 파티션을 기준으로 접근해야 함              컴파일된 .exe 파일의 첫번째 명령어가 100번지에 있는 프로시저 콜이라고 가정하면…         해당 파일을 파티션에 로드해 실행했을 때 : 0 + 100번지로 접근 (파티션의 시작 주소) + 100번지로 접근         IBM360모델 : 정적 재배치 (Static Relocation)            프로그램이 메모리에 로드될 때, 파티션을 기준으로 접근하도록 명령어 수정                    링커가 프로그램의 어떤 부분이 리로케이트되어야 하는지 알아야 함                           주소 바인딩 (Address Binding) : 프로세스의 논리적 주소를 물리적 메모리 주소로 연결     주소 공간 (address space) : 프로세스가 메모리에 접근할 때 사용하는 주소들의 집합            각 프로세스들은 자신들만의 주소 공간을 가짐 -&gt; logical address           프로그램이 어떤 주소를 사용해도, 메인 메모리에 할당된 주소를 찾아가도록 해야 함            논리 주소 (logical address) : CPU에서 사용하는 주소. 메모리 내 프로세스의 독립적인 공간       물리 주소 (physical address) : 메인 메모리에서 사용하는 주소. 하드웨어에 의해 정해진 주소 공간              … 그러므로 프로그램이 할당된 실제 메모리 주소 공간의 위치는 프로그램을 실행하는 CPU에 전혀 영향을 미치지 않음         그럼 어떻게 각각의 프로세스들에게 서로 다른 주소 공간을 제공할 수 있을까?      MMU의 재배치 레지스터 (Relocation Register) : 프로세스의 논리 공간을 메모리의 물리 공간으로 연속해 매핑     동적 재배치 (Dynamic relocation) : 프로세스의 논리 주소를 메모리의 물리 주소으로 변경            베이스 레지스터 (Base Register) : (파티션의 시작 주소)       리미트 레지스터 (Limit Register) : (파티션의 크기)                 현재 프로그램이 파티션에 로드되었을 때, 프로그램이 로드된 파티션의 크기를 리미트 레지스터의 값에 저장   CPU는 메인 메모리에서 주소가 사용 가능한지 여부를 생각하지 않고, 명시된 그대로 물리 주소를 사용하려고 함   CPU가 명령어를 수행할 때마다, 프로세스가 참조하려는 주소에 베이스 레지스터의 값을 더해 수행 (Relocation)   CPU가 명령어를 수행할 때마다, 프로세스가 참조하려는 주소가 리미트 레지스터의 값과 동일하거나 큰지 확인 (Protection)            O : 프로텍션 바이오레이션 (Protection Violation) 발생시켜 메모리 참조를 중단       X : 프로세스가 참조하려는 주소에 베이스 레지스터의 값을 더한 값을 메모리 버스에 보냄              Q. 그럼 베이스 레지스터 &amp; 리미트 레지스터를 사용하면 이젠 더 이상 문제가 없는걸까?         모든 메모리 참조마다 덧셈과 비교 연산이 요구되기에, 비교적 시간이 오래 걸림 : 특히 덧셈 연산이!                블로트웨어 (Bloatware) : 메모리의 크기를 증가하는 속도를 소프트웨어의 크기가 증가하는 속도가 역전                             정적 메모리 파티션 (Fixed memory partitions) : 메모리를 파티션 여러 개로 미리 나누고 프로세스 할당                Multiple input Queues : 도착한 작업을 크기에 맞는 가장 작은 파티션에 넣음         Single input Queue : 도착한 작업을 수용할 큐를 하나만 배정, 먼저 도착한 작업을 먼저 실행시킴                             정적 메모리 파티션은 메모리가 시스템이 구동할 모든 프로세스를 적재 가능한 용량을 가져야 성립하나,             시스템이 구동할 모든 프로세스들이 필요한 메모리의 전체 크기는 실제 RAM 용량보다 크다.       프로그램이 시작하기 전에 이미 실행 중인 프로세스들이 적재되어 있다.            … 모든 프로세스들을 계속 적재하기엔, 물리 메모리 크기에 한계가 있다는 문제에 대해, 2가지 해결책이 제시되었다.         Swapping : 한 프로세스의 전체 이미지가 메모리로 적재되어 실행되다가 실행되지 않으면 디스크로 이동     Virtual Memory : 한 프로세스의 전체 이미지가 아닌 일부만 메모리에 있어도 프로세스의 실행이 가능      스와핑 (Swapping) : 메모리에 로드된 프로세스 중에 장기간 미사용된 것을 하드 디스크에 이미지 형태로 저장     프로세스 이미지 (Process Image) : 프로그램이 메모리에 로드되고 실행되어 데이터가 변경된 프로세스            하드 디스크에 존재하는 .exe, .app에 데이터가 변경되었기에 이를 하드 디스크의 backing store에 저장                    swap-out : 메인 메모리 -&gt; Backing store           swap-in : Backing store -&gt; 메인 메모리                                 … backing store는 메인 메모리의 모든 프로세스가 swap-out될 때 데어터의 소실 없이 저장할 수 있어야 한다.         그러므로, 하드 디스크에서 backing store이 할당받는 크기는 최소 메인 메모리의 크기라 예상할 수 있다.            (a) 각 프로그램의 데이터 세그먼트가 늘어날 공간을 미리 확보   (b) 각 프로그램의 세그먼트를 프로그램 텍스트 / 데이터 세그먼트 / 스택 세그먼트로 나눔            프로그램 텍스 위의 데이터 세그먼트와 스택 세그먼트가 서로를 향해 자라게끔 함                    힙 (Heap) 영역 (Room for growth) : 사용자가 동적으로 할당할 영역                            malloc, calloc 등의 명령어로 관리                                                   동적 메모리 파티션 (Dynamic memory partitions) : 프로그램이 메모리에 로드될 때마다 파티션을 나누고 할당     운영체제가 동적으로 할당된 프로세스를 관리 : 힙 영역이 커지므로, 프로세스의 확장을 위한 공간이 할당되어야 함         (b) Bit Maps 사용 : 맵에 X비트를 관장할 Y개의 할당 단위 (allocation unit)            단위 유닛이 메모리에 할당되어 있으면 유닛의 값을 1, 할당되어 있지 않으면 0 (flag bit)                   할당 단위가 작아지면? : 유닛의 개수 Y가 커진다.                Y를 표현할 flag bit가 많이 필요하므로, 맵의 크기가 커져 맵을 탐색할 때의 성능이 저하된다.                 할당 단위가 커지면? : 유닛의 개수 Y가 작아진다.                Y를 표현할 flag bit가 적게 필요하므로, 비트맵의 공간이 작아진다.         마지막 프로세스에 빈 공간 역시 커져 더 많은 메모리 공간이 낭비될 가능성이 있다.                   … Bit Maps의 문제점 : 프로세스가 k개의 할당 단위를 요구할 때, 맵에서 k개의 0비트를 연속해서 찾아야 한다.       (c) Linked Lists 사용 : 메모리의 낮은 주소부터 링크드 리스트의 노드가 있음            각 엔트리는 P (프로세스) or H (홀)을 표현하는 flag, 시작 주소, 길이, 다음 엔트리를 가리키는 포인터로 구성                   프로세스 종료 시 Linked Lists를 업데이트하는 방법                종료되는 프로세스는 일반적으로 2개의 이웃을 가짐 → 이웃은 다른 프로세스가 차지한 공간이거나 빈 공간                             (a) X에 해당되는 엔트리를 X에서 H로 바꿔 갱신     (b), (c) 2개의 엔트리를 통합해 하나로 표현     (d) 3개의 엔트리를 통합해 하나로 표현      Contiguous Memory Allocation : 메모리에 새로 생성된 프로세스들을 위한 메모리 공간 할당     메모리 단편화 (Memory fragmentation) : 메인 메모리에 흩어진 홀들이 불연속적으로 할당된 상태            프로세스 생성 &amp; 종료 반복 → scattered holes       홀 (Hole) : 메인 메모리에서 프로세스가 할당되지 않은 영역           외부 단편화 (External fragmentation) : 프로세스를 할당할 크기가 충분하나, 메모리 단편화로 할당이 불가능한 상태         First-fit : 프로세스 크기보다 크거나 같은 홀을 탐색하는 순서 중에서 가장 먼저 찾은 홀에 프로세스 할당         Best-fit : 할당할 프로세스 크기와 홀의 크기 차이가 가장 작은 홀에 프로세스 할당         Worst-fit : 할당할 프로세스 크기와 홀의 크기 차이가 가장 큰 홀에 프로세스 할당            Best-fit을 사용하였다가 다른 프로세스가 쓰지 못할 정도의 홀이 생겼을 때를 위한 대안                 Compaction : 메모리 여러 곳에 흩어져있는 홀들을 강제로 하나로 병합            홀을 옮기는 오버헤드가 매우 크고, 어느 홀을 옮겨야 빠르게 합칠 수 있는지에 대한 최적 알고리즘이 존재하지 않음              일반적으로 할당 속도는 First-fit가 가장 빠르며, 메모리 이용률은 First-fit와 Best-fit이 비슷하다.         하지만 Best-fit을 사용하더라도, 외부 단편화로 인해 여전히 전체 메모리의 1/3 정도를 낭비한다.     ","categories": [],
        "tags": ["Operation System"],
        "url": "/os6/",
        "teaser": null
      },{
        "title": "[Operation System] 7. Paging",
        "excerpt":"페이징 (Paging) : 프로그램과 메모리를 일정한 크기로 나눔      가상 주소 (Virtual address) : 프로그램이 가상 메모리에서 참조하는 주소            가상 메모리 (Virtual Memory)가 있다면, 각 프로그램은 자신의 고유한 가상 주소 공간을 가짐                    가상 메모리 사용 O : 가상 주소가 그대로 메모리 버스에 실려 물리 주소가 됨           가상 메모리 사용 X : 가상 주소가 MMU에 의해 물리 주소로 매핑                                 가상 주소 공간과 물리 주소 공간은 고정된 크기 단위의 유닛들로 동일하게 나뉜다.            가상 페이지 (Virtual Page) : 가상 주소 공간을 나눈 조각. 각 페이지는 연속된 주소를 가짐       페이지 프레임 (Page Frame) : 물리 메모리를 나눈 조각.                   다음 그림에서는 가상 주소 공간을 64KB, 물리 메모리 공간을 32KB, 유닛 크기는 4KB로 가정하고 있다.                논리 주소 (logical address) : 세그먼트 (segment) + 오프셋 (offset)                세그먼트 (segment) : 64KB의 고정된 길이와 시작 위치으로만 구성         오프셋 (offset) : 세그먼트의 시작 지점에서 실제 주소까지 떨어진 거리                 가상 주소 (virtual address) : single 32-bit unsigned integer                가상 페이지는 16진수로 표현 (16bit) : 0x00000000 ~ 0xffffffff의 범위 (4096bit=4KB)                 물리 주소 (physical address) : 물리 메모리에서 각각의 셀 (cell)의 주소                페이지 프레임은 가상 페이지가 매핑되는 물리 메모리의 일부분(4096bit=4KB)                        명령어 MOV REG, 0을 수행한다고 가정해보자.             이 명령어에서 접근하는 가상 주소 0는 MMU로 전달된다.       MMU는 해당 가상 주소가 가상 페이지 0에 속한 것임을 확인한다.       MMU는 가상 페이지 0에 매핑된 물리 주소의 페이지 프레임이 2임을 계산한다.       가상 주소 0은 물리 주소 8192로 변환되고, 이 물리 주소가 메모리 버스에 실린다.            … 가상 페이지를 페이지 프레임에 매핑하는 것만으론, 가상 주소 공간이 물리 주소 공간보다 큰 문제를 해결하지 못한다.    페이지 폴트 (Page Fault) : 페이지가 메모리에 매핑되어 있지 않음을 파악하면 CPU에서 트랩 발생     present 비트 : 어떤 페이지가 실제 메모리에 존재하는지 표현하는 비트 (가상 페이지에 X로 표현)            페이지가 메모리에 매핑되어 있지 않으면, CPU에서 트랩을 발생시켜 운영체제에 이를 알림           Page Fault가 발생하면, 운영체제는 적게 사용되고 있는 페이지 프레임을 하나 선택            선택한 페이지가 수정되었다면 (dirty 상태) 이를 디스크에 기록       선택한 페이지가 수정되지 않았다면 (clean 상태) 디스크에 존재하는 것과 동일하니 기록하지 않음       선택한 기존 페이지의 내용을 지우고, 참조하려는 페이지의 내용을 페이지 프레임에 적재       선택한 기존 페이지 프레임을 X로, 참조한 페이지 프레임을 숫자로 매핑시켜 가상 페이지 맵 수정       트랩이 발생한 명령어를 다시 실행              명령어 MOV REG, 24576을 수행할 때 Page Fault가 발생해 OS에서 페이지 프레임 1을 교체한다고 가정해보자.         가상 페이지 1이 더 이상 매핑되지 않음 (X)을 표시한다.     가상 페이지 7이 페이지 프레임 1에 매핑되었음을 표시한다.      페이징 테이블 (Page Table) : 가상 페이지 번호 (VPN)를 페이지 프레임 번호 (PFN)로 매핑      위의 매핑 정보를 바탕으로 가상 주소 8196를 물리 주소 24580로 변환하는 과정을 가정해 살펴보자.               16비트 크기를 갖는 가상 주소는 VPN와 오프셋으로 구분된다.                페이지 번호는 페이지 테이블의 인덱스로 사용된다.                 페이지 테이블에는 VPN에 대응되는 PFN이 기록되어 있다.                present가 1이면, 페이지 테이블의 PFN 3과 가상 주소의 오프셋 12가 결합해 물리 주소가 된다.                 물리 주소를 주소 출력 레지스터를 통해 메모리 버스로 전달해 참조한다.              페이지 테이블엔 디스크에 존재하는 페이지의 디스크 주소에 대한 정보가 없음 (Page Fault : 운영체제 내부에서 처리)            메모리에 존재하는 페이지 주소에 대한 정보만 존재 : 하드웨어가 가상 주소를 물리 주소로 변경할 때 사용                 페이지 테이블의 각 페이지에 존재하는 정보            페이지 프레임 번호 (PFN) : 가상 주소를 물리 주소로 매핑                    해당 페이지가 매핑된 물리 주소 결정                       Present 비트 : PFN이 유효한지 아닌지 결정 (가상 주소가 사용될 때마다 확인)                    0 (X)이면 해당 엔트리에 대응되는 페이지가 물리 메모리에 존재하지 않는 상태 (트랩 발생)                       Protection 비트 : 어떤 접근이 허용되는지 표시                    write, read, execute                       Modify 비트 : 페이지가 수정되었는지 아닌지 확인                    페이지의 내용이 write되면, 하드웨어가 자동으로 비트를 1로 세팅                            Modify 비트가 1 (dirty)이면, 페이지 프레임이 교체될 때 디스크에 기록되어야 함               Modify 비트가 0 (clean)이면, 페이지 프레임이 교체될 때 새로운 내용으로 덮어씌워도 됨                                               Reference 비트 : 해당 페이지가 write 또는 read로 접근되었을 때 설정                    운영체제가 Page Fault의 처리를 위해 교체할 페이지 프레임을 선택할 때 사용                       Cashing Disabled 비트 : 해당 페이지가 캐싱될 수 있는지 여부                    페이지가 메모리가 아닌 장치 레지스터에 매핑되어 있을 때 실행                                          64bit 주소를 사용하는 컴퓨터는 가상 주소 공간이 2^64byte       가상 주소 공간의 한 페이지가 4KB = 2^12byte이면,                    페이지 테이블의 엔트리 개수는 전체 공간을 한 페이지로 나눈 2^52개           엔트리 하나당 4byte의 크기를 가진다면, 페이지 테이블의 크기는 2^52 * 4byte                            … 페이징은 다음 두 가지 문제를 해결해야 한다.         가상 주소 공간이 커지면, 페이지 테이블의 크기 (= 페이지 테이블 엔트리의 개수) 또한 증가한다.                페이지 테이블을 유지하기 위해 필요한 메모리의 크기가 클 수 있음                 가상 주소에서 물리 주소로의 변환이 빠르게 이루어져야 한다.                메모리를 참조하는 오버헤드가 작아야 함                  TLBs (Translation Lookaside Buffers) : 페이징의 속도를 높이고, 큰 가상 주소 공간을 지원하는 기법      대부분의 프로그램들은 적은 개수의 페이지를 집중적으로 참조하는 경향이 있다.         페이지 테이블의 일부 엔트리만이 높은 빈도로 참조되고, 나머지 엔트리는 낮은 빈도로 참조된다.         TLB : 페이지 테이블의 참조 없이 가상 주소를 물리 주소로 매핑할 수 있는 작은 크기의 메모리            MMU 내부에 존재하며, 적은 개수의 엔트리를 가짐                    각각의 TLB 엔트리는 한 페이지에 대한 정보를 포함                                        MMU는 주소 변환을 할 때 요청된 가상 페이지가 TLB에 있는지 검색     가상 페이지가 존재하고 보호코드를 위반하지 않으면, 대응되는 페이지 프레임을 사용하여 주소 변환을 실행     TLB가 존재하지 않으면, TLB miss 발생. MMU는 페이지 테이블에서 해당 페이지 테이블 엔트리를 검색     그리고 TLB 엔트리 중 하나를 선택해 그 내용을 교체. 페이지 테이블에 없는 수정 비트는 페이지 테이블에 기록     찾은 페이지 테이블 엔트리를 TLB 엔트리에 기록 (이때 다시 참조한다면 TLB hit로 처리)     새로운 정보가 적재될 때는 페이지 테이블 엔트리에 있는 내용이 적재         메모리 계층 구조에서 발생할 수 있는 miss의 경우의 수 : 2^3가지 -&gt; 실제 발생 가능한 경우의 수 : 5가지      \t   \t\t   \t\t\t  Cache         TLB         Virtual Memory         발생 가능 여부 \t\t\t  설명 \t\t   \t   \t   \t\t   \t\t\t  hit         hit         hit         가능 (최선) \t\t\t  (1) TLB가 hit이므로, 페이지 테이블을 확인할 필요 없이 가상 주소를 물리 주소로 변환 (메인 메모리 접근 X) (2) Cache가 hit이므로, 변환한 물리적 주소로 캐시에 접근하면 데이터를 가져올 수 있음 \t\t   \t\t   \t\t\t  miss         hit         hit         가능 \t\t\t  (1) TLB가 hit이므로, 페이지 테이블을 확인할 필요 없이 가상 주소를 물리 주소로 변환 (메인 메모리 접근 X) (2) Cache가 miss이므로, 변환한 물리적 주소로 캐시에 접근하면 데이터를 가져올 수 없음 (3) Virtual Memory가 hit이므로, 캐시에 데이터를 불러오기 위해 메모리에 접근하면 데이터를 가져올 수 있음 (4) 메모리에서 캐시로 가져온 데이터를 CPU에 전달 \t\t          \t\t\t  hit         miss         hit         가능 \t\t\t  (1) TLB가 miss이므로, 페이지 테이블에 접근 (메인 메모리 접근 O) (2) Virtual Memory가 hit이므로, 가상 주소를 물리 주소로 변환 (3) Cache가 hit이므로, 변환한 물리 주소로 캐시에 접근해 캐시에 있는 데이터를 CPU에 전달 \t\t          \t\t\t  miss         miss         hit         가능 \t\t\t  (1) TLB가 miss이므로, 페이지 테이블에 접근 (메인 메모리 접근 O) (2) Virtual Memory가 hit이므로, 가상 주소를 물리 주소로 변환 (3) Cache가 miss이므로, 변환한 물리 주소로 캐시에 접근하면 캐시 내에 데이터가 없음 (4) 메인 메모리에서 해당 데이터를 캐시로 가져와 CPU에 전달 \t\t          \t\t\t  miss         miss         miss         가능 (최악) \t\t\t  (1) TLB가 miss이므로, 페이지 테이블에 접근 (메인 메모리 접근 O) (2) Virtual Memory가 miss이므로 (Page fault), 하드 디스크에서 데이터를 직접 가져와 페이지 테이블을 업데이트 (3) 이제 TLB가 miss &gt; hit이므로, 가상 주소를 물리 주소로 변환 가능. (4) Cache가 miss이므로, 변환한 물리 주소로 캐시에 접근하면 캐시 내에 데이터가 없음 (5) 메인 메모리에서 해당 데이터를 캐시로 가져와 CPU에 전달 \t\t          \t\t\t  miss         hit         miss         불가능 \t\t\t  메모리 계층 구조 위반 : Page fault인데 TLB가 hit일 수 없음 \t\t          \t\t\t  hit         hit         miss         불가능 \t\t\t  메모리 계층 구조 위반 : Page fault인데 TLB가 hit일 수 없음 \t\t          \t\t\t  hit         miss         miss         불가능 \t\t\t  메모리 계층 구조 위반 : Page fault인데 Cache가 hit일 수 없음 (캐시에 데이터가 있을 수 없음) \t\t   \t                TLB miss인 경우 : 페이지 테이블에는 정보가 있지만, TLB에 그 정보가 들어있지 않을 때                해결책 : 페이지 테이블의 페이지 엔트리 내 데이터를 가져와 TLB에 넣음                 Page fault인 경우 : TLB에도 정보가 없고, 페이지 테이블에도 그 정보가 없을 때                운영체제는 권한을 받아 하드 디스크의 데이터를 페이지 테이블에 가져오고, TLB에 가져온 데이터를 넣음                  다단계 페이지 테이블 (Multi-level Page Table)     페이지 테이블을 페이지 프레임 크기로 나눔            해당 페이지 테이블의 페이지가 invalid하면 메모리에 할당하지 않음       기존의 단일한 페이지 테이블을 트리 구조로 연결           페이지 디렉토리 (Page Dictionary) : 페이지 프레임의 유무를 확인하는 자료구조            적어도 하나의 PFN이 valid하다면, 페이지 디렉토리의 해당 엔트리는 존재함                        기존의 페이지 테이블에서, 가운데에 위치한 페이지는 메모리에 할당되어 있음     다단계 페이지 테이블에서, 가운데에 위치한 페이지는 메모리에 할당되어 있지 않음       다단계 페이지 테이블에서의 모든 페이지 테이블은 항상 메모리에 유지될 필요가 없다.          필요한 페이지 테이블만 메모리에 할당해 절약할 수 있음   페이지 디렉토리로 물리 메모리의 빈 공간에 페이지 테이블 엔트리를 생성 가능   기존의 TLB Miss가 2번 늘어나 주소 변환이 2번 필요하고, TLB Miss를 처리해 메모리를 최적화하는 로직이 복잡해짐   역 페이지 테이블 (Inverted Page Table)     빠른 하드웨어 레지스터로 구성된 단일한 페이지 테이블 사용            페이지 테이블의 각 엔트리는 하나의 메모리 프레임에 대응           크기가 고정된 페이지 테이블에 프로세스를 맵핑            프로세스 실행 시 운영체제는 메모리에 존재하는 프로세스의 페이지 테이블 전체를 하드웨어 레지스터 배열에 적재           논리 주소는 PID, PFN, offset으로 구성   물리 주소는 MFN와 offset으로 구성         논리 주소의 PID와 PFN 정보를 바탕으로 페이지 테이블에서 동일한 엔트리 탐색   페이지 테이블에서 PID와 PFN가 일치하는 (MFN)번째 항목을 발견   MFN과 Offset 정보를 바탕으로 확인된 메모리 주소에 접근           64bit를 사용하는 컴퓨터에서 256MB의 물리 메모리가 4KB 페이지 프레임 2^18개로 구성되었다면,                페이지 테이블을 사용할 때의 페이지 테이블의 엔트리는,                        가상 주소 공간 2^64byte을 한 페이지 프레임의 크기 4KB = 2^12byte로 나눈 2^52개                             역 페이지 테이블을 사용하는 페이지 테이블의 엔트리는 물리 메모리의 페이지 프레임의 개수와 같으므로,                        물리 메모리 256MB = 2^28byte를 한 페이지 프레임의 크기 4KB = 2^12byte로 나눈 2^16개                                         프로세스 실행 중엔 페이지 테이블을 위한 추가적인 메모리 참조가 필요 없음 (프로세스 확장이 페이지 테이블과 무관)   페이지 테이블이 커질수록 구현을 위한 비용이 증가하고, 최악의 경우 페이지 테이블 전체를 적재해야 함 ex) 문맥 교환  ","categories": [],
        "tags": ["Operation System"],
        "url": "/os7/",
        "teaser": null
      },{
        "title": "[Operation System] 8. Page Replacement Algorithm",
        "excerpt":"페이지 교체 알고리즘 (Page Replacement Algorithm) : 페이지 폴트 시 교체할 페이지 선택      교체한 페이지가 다시 필요해져 페이지 폴트가 발생하는 비율을 줄여야 함 : 자주 사용되지 않을 페이지를 선택해야 함            제거할 페이지 중 최고의 페이지는 가장 긴 시간동안 접근하지 않을 페이지           최적 페이지 교체 알고리즘 (Optimal Page Replacement Algorithm) : 가장 사용하지 않을 페이지 교체     운영체제가 모든 페이지 참조를 수집했다고 가정하면, 각 페이지들이 몇개의 명령어 뒤에 처음으로 참조되는지 알 수 있음   그 중 가장 많은 명령어 뒤에 참조되는 페이지를 교체      페이지 폴트가 발생했을 때, 운영체제가 각 페이지들이 어느 시점에 참조되는지 알 수 없음         프로세스를 처음 돌린 뒤에 수집된 정보를 바탕으로 사용 가능      NRU (Not Recently Used) 페이지 교체 알고리즘 : 최근에 사용되지 않은 페이지 교체     가상 메모리를 지원할 때, 각 페이지마다 운영체제가 페이지 사용 정보를 수집하기 위한 2개의 상태 비트를 유지            R (Reference 비트) : 페이지가 참조될 때마다 설정 (read/write)       M (Modify 비트) : 페이지가 수정될 때 마다 설정 (clean/dirty)           최근에 참조되지 않은 페이지를 참조된 페이지와 구별하기 위해 주기적으로 (clock tick마다) R비트를 0으로 초기화   페이지를 4개의 클래스로 분류            클래스 0 : R = 0, M = 0       클래스 1 : R = 0, M = 1       클래스 2 : R = 1, M = 0       클래스 3 : R = 1, M = 1           페이지 폴트가 발생했을 때, 낮은 클래스에 있는 페이지 중 하나를 랜덤으로 교체            참조도, 수정도 안된 클래스 3에 속한 페이지가 있으면 내쫓고,       없으면 최소 한 사이클에서 참조되지 않은 클래스 2에 속한 페이지가 있으면 내쫓고,       없으면 자주 참조되지만 수정되지 않은 클래스 1에 속한 페이지가 있으면 내쫓고,       없으면 참조도, 수정도 이루어진 클래스 0에 속한 페이지가 있으면 내쫓는다.              가장 최근에 참조되지 않은, 변경된 페이지의 교체가 집중적으로 참조된, 변경되지 않은 페이지의 교체보다 좋음    FIFO 페이지 교체 알고리즘 : 메모리에 가장 먼저 로드된 페이지 교체     메모리에 페이지들이 들어온 순서대로 링크드 리스트를 sorting   페이지 폴트가 발생하면, 맨 앞에 들어온 것을 교체           메모리에 오래 있던 페이지가 자주 사용되는 페이지일 수 있음                 벨레이디의 모순 (Belady's anomaly) : 페이지 프레임이 늘어나면, 페이지 폴트의 개수가 오히려 느는 경우           Second-Chance 페이지 교체 알고리즘 : 메모리에 가장 먼저 로드된 페이지의 R을 검사한 후 교체     메모리에 페이지들이 들어온 순서대로 링크드 리스트를 sorting   페이지 폴트가 발생하면, 가장 오래된 페이지의 R을 검사            R = 0이면, 이 페이지는 최근에 사용되지 않은 페이지이므로 교체해도 됨       R = 1이면, 이 페이지를 맨 뒤로 옮기고, R를 0으로 초기화 (적재 시간도 현재시간으로 갱신)하고 다시 검사              자주 참조되는 페이지를 교체할 가능성이 있는 FIFO를 개선         하지만, 페이지를 리스트 맨 뒤로 이동시켜아 하기 때문에 동작의 효율성이 떨어질 수 있음      Clock 페이지 교체 알고리즘 : 시계 모양 원형 리스트를 구성하고, 화살표가 가리킨 페이지의 R을 검사     메모리에 페이지들이 들어온 순서대로 원형 리스트를 sorting   페이지 폴트가 발생하면, 화살표가 가리키는 페이지의 R을 검사            R = 0이면, 최근에 사용되지 않은 페이지이므로, 새로운 페이지 삽입 후 화살표를 다음 페이지로 이동       R = 1이면, 이 페이지의 R를 0으로 초기화하고 그 다음 페이지를 검사              LRU 페이지 교체 알고리즘 : 가장 오랫동안 사용되지 않은 페이지를 교체     메모리에 페이지들이 들어온 순서대로 링크드 리스트를 sorting            가장 최근에 사용된 것을 리스트의 맨 앞에, 가장 오래된 것을 리스트의 맨 뒤에 오게끔 배치           페이지 폴트가 발생하면, 가장 맨뒤에 있는 페이지를 추출      모든 메모리의 참조마다 리스트를 갱신해야 함 : 리스트에서 페이지를 탐색, 삭제, 이동하는 작업은 오래 걸림    LRU의 하드웨어 구현 1 : 64bit 카운터     카운터가 명령을 실행할 때마다 C값을 1씩 증가   각 페이지 테이블 엔트리는 카운터 값을 저장할 수 있는 공간을 가짐   메모리가 참조될 때마다 참조된 메모리를 담고 있는 페이지를 가리키는 페이지 테이블 엔트리에 C값 저장   페이지 폴트가 발생하면, 모든 페이지 테이블 엔트리의 C값을 조사해 가장 적은 값을 갖는 페이지를 교체      LRU의 하드웨어 구현 2 : N*N bit로 구성된 행렬을 갖는 LRU 하드웨어     N개의 페이지 프레임 -&gt; N*N bit로 구성된 행렬 : 행렬의 모든 값의 초기값은 0   페이지 프레임 k가 참조되면, LRU 하드웨어는            행렬에서 k번째 행의 모든 비트를 1로 설정       k번째 열의 모든 비트를 0으로 설정           행의 이진 값이 가장 작은 행에 대응되는 페이지 프레임이 가장 과거에 참조된 것           페이지가 0,1,2,3,2,1,0,3,2,3 순으로 참조되었다고 가정하자.         일단 1행을 모두 1로 0열을 0으로 초기화     1행을 모두 1로, 1열을 모두 0으로 초기화     페이지 폴트가 발생하면, 행 값이 제일 낮은 프레임을 교체                만약 그림 j에서 페이지 폴트가 발생하였으면, 2행이 가장 낮으므로 프레임 2를 교체                  LRU의 소프트웨어 구현 1 : NFU (Not Frequently Used)     각 페이지마다 각 페이지들이 얼마나 자주 참조되었는지 알려줄 소프트웨어 카운터를 유지 (카운터의 초기값은 0)   클록 인터럽트가 발생할 때마다 운영체제는 메모리의 모든 페이지를 검사하여 R의 값을 소프트웨어 카운터에 더함   페이지 폴트가 발생하면, 가장 적은 카운터 값을 갖는 페이지가 교체      NFU에는 잊어버리는 기능이 부재되어 있다.         다중 패스 컴파일러의 경우 : 패스 1에서 자주 참조된 페이지들은 높은 카운터 값을 가짐, 이는 패스 2에서도 유지     만일 패스 1이 그 이후 다른 패스들보다 더 긴 실행 시간을 가진다면 혹은 패스 1에서 더 많은 참조가 일어난다면, 패스 1에서 실행된 페이지들은 그 이후 패스에서 사용되는 페이지들에 비해 더 큰 카운터 값을 가짐                그러므로 패스 1에 사용되던 페이지 대신 현재 패스에 사용하는 유용한 페이지들을 교체                  LRU의 소프트웨어 구현 2 : 에이징 (Aging)     NFU를 기반으로, 다음의 사항을 변경한다.            R를 더하기 전에 오른쪽으로 1비트 시프트한다.       R는 오른쪽 비트가 아닌 왼쪽 최상위 비트에 추가된다.                       시간 순서를 구별할 정보를 기록                LRU : 오직 하나의 비트로 참조 여부만 기록해, 페이지 3, 5 중 어떤 페이지가 더 먼저 참조되었는지 모름         에이징 : 시간 순서를 구별할 정보를 기록해, 2번의 클록 틱 전에 1번 더 참조된 페이지 5 대신 3 교체                 과거에 대한 정보를 제한                NFU : 과거에 대한 정보를 모두 기억해 10번째 전에 참조되었는지, 100번 전에 참조되었는지 알 수 없다.         에이징 : 최대 N번 전에 정보를 기록할 N비트만이 존재해, 과거에 대한 정보를 제한된다.                  워킹 세트 알고리즘 (The Working Set Page Replacement Algorithm) : 페이지 집합 관리           스레싱 (Thrashing) : 멀티 프로그래밍의 정도가 높아 페이지 폴트가 계속 발생해 페이지 교체 시간이 길어짐                멀티 프로그래밍의 정도가 높은 경우 : 여러 프로세스로 인해 프로세스가 충분한 페이지를 가지지 못함                        어느 순간부터 CPU 점유율이 하락 (프로세스는 스와핑하느라 바쁜데, CPU는 아무것도 안한다.)                                                 Demand Paging : 실제로 필요할 때 (요청이 있으면) 그 page를 메모리에 올린다.                프로세스가 시작될 때 메모리에는 어떤 페이지도 존재하지 않음         CPU가 첫 명령어를 fetch하면 페이지 폴트를 통해 운영체제가 로드                 참조의 지역성 (Locality of reference) : 프로세스는 작은 페이지만을 집중적으로 참조하는 경향이 있음                locality set : 집중적으로 참조되는 해당 페이지의 집합                     워킹 세트 (Working Set) W(K, T) : 프로세스가 현재 사용하고 있는 페이지의 집합            워킹 세트의 locality set : 프로세스가 일정 시간 원활히 수행되기 위해 한번에 올라와야 하는 페이지들의 집합              워킹 세트를 (시간 T)에 대해, 가장 최근에 (횟수 K번) 발생한 메모리 참조에 의해 사용된 페이지의 집합이면,         뒤의 페이지가 앞의 페이지를 포함하니 K를 늘리수록 커지다가, (가상 페이지의 개수가 한정되어) 한 곳에 수렴              워킹 세트 모델 (Working Set)            PrePaging : 각 프로세스의 워킹 세트를 추적하다, 프로세스가 실행되기 전 그 프로세스의 워킹 세트 미리 로드       주기적인 인터럽트가 R을 일정 시간마다 초기화       페이지 폴트가 발생하면, 페이지 테이블을 스캔해서 쫓아낼 페이지를 탐색       해당 프로세스의 워킹 세트 전체를 한꺼번에 메모리에 올라갈 수 있는 경우에만 메모리에 할당                    그렇지 않을 경우, 모든 페이지 프레임들을 모두 반납시키고 디스크로 swap-out (스레싱 방지)                              워킹 세트 윈도우 (Working Set Window) : 올라올 워킹 세트를 결정 (워킹 세트 윈도우의 크기 : T)            페이지가 참조된 시점부터 T 시간 동안 메모리에 유지하고, 그 시점이 지나면 메모리에서 지움           메모리에 있는 프로세스들의 워킹 세트 크기의 합이 페이지 프레임의 수보다 클 경우 : 일부 프로세스를 swap-out            남은 프로세스의 워킹 세트가 메모리에 모두 올라가게 해 이를 우선적으로 충족 (멀티프로그래밍의 정도를 줄임)           워킹 세트를 모두 할당한 후에도 페이지 프레임이 남으면, swap-out된 프로세스를 메모리에 올려 워킹 세트 재할당           현재 가상 시간 (Current virtual time) : 프로세스가 시작된 후에 CPU를 실제 사용한 시간     마지막으로 사용한 시간 (Time of last use)                 페이지의 현재 가상 시간이 2204일 때 페이지 폴트가 발생하면,                페이지 테이블을 모두 스캔하면서 R을 체크한다.         R = 1 : 마지막으로 페이지를 사용한 시간을 현재 가상 시간으로 바꾼다.         R = 0 : age = (현재 가상 시간 - 마지막으로 페이지를 사용한 시간)와 T 비교                        age &gt; T : 워킹 세트에 그 페이지가 포함되어 있지 않으므로, 그 페이지를 지우고 게속 스캔한다.             age &lt;= T : 가장 큰 age를 만드는 페이지를 기억하고 계속 스캔한다.                             마지막까지 스캔했을 때 (모든 엔트리가 age &lt;= T이면), 가장 큰 age를 만드는 페이지를 지운다.         모든 엔트리가 R = 1이면 (가장 큰 age를 만드는 페이지를 모른다면), 한 페이지를 랜덤으로 지운다.                  세그멘테이션 (Segmentation) : 하나의 가상 주소를 제공하는 페이징과 달리, 여러 개의 가상 주소 제공     프로세스를 논리적 내용을 기반으로 나누어서 메모리에 배치            세그멘테이션 기법에서의 프로세스는 세그멘트 (segment)의 집합                    각 세그먼트는 자기만의 선형적인 주소 공간을 가짐                       페이징 기법에서는 주소 공간이 서로 충돌될 수 있지만, 세그멘테이션에서는 동적으로 테이블이 커지거나 줄어듬              세그먼트 테이블 : 각 엔트리의 논리 주소는 &lt;segment-number, offset&gt;            페이징과 달리 세그먼트의 크기는 일정하지 않기에 테이블에 limit 정보가 추가로 담겨 있음       만약 세그먼트의 크기를 초과하는 주소가 들어오면 인터럽트가 발생해 프로세스가 강제 종료                        논리 주소 (2, 100) : 물리 주소 4400번지     논리 주소 (1, 500) : 인터럽트로 인해 프로세스가 강제로 종료 (범위 벗어남)         세그멘테이션의 장점            보호 : 세그먼테이션도 페이징처럼 r, w, x를 테이블에 추가하는데, 프로세스를 논리적으로 나눠 비트 설정 간단       공유 : 세그먼테이션은 정확히 code 영역만 나누기에 다른 영역을 포함할 확률이 높은 페이징보다 더 효율적              …하지만 세그멘테이션은 외부 단편화 문제를 해결하지 못해, 현재는 페이징 기법을 대부분 사용한다.          외부 단편화 : 메모리 할당을 처음 시작할 때 크기가 서로 다른 프로세스로 인해 다양한 크기의 홀이 발생 (checkerboarding)                세그먼트를 논리적인 단위로 나눈 세그멘테이션 역시 외부 단편화로 인해 메모리 낭비가 큼                 세그멘테이션을 페이징 (Paged segmentation) : 펜티엄 (Pentium)                cs, ds, ss를 각각의 세그먼트가 아닌 하나의 주소 공간으로 통일해서 사용                        그러므로 cs, ds, ss는 다 같은 셀렉터 값을 가짐                             세그먼트와 페이지가 동시에 존재하기 때문에 주소 변환도 2번                        CPU의 세그먼트 테이블에서 주소 변환, 그리고 다음 페이지 테이블에서 주소 변환                                     ","categories": [],
        "tags": ["Operation System"],
        "url": "/os8/",
        "teaser": null
      },{
        "title": "[Docker] 1. Virtualization",
        "excerpt":"가상화 (Virtualization) : 컴퓨터 자원 (Computer Resource)의 추상화      하드웨어 종속성 배제 : 물리적인 하드웨어 자원을 논리적인 단위로 나누고 이를 통합해 가상의 자원을 활용   리소스 가상화 (Resource Virtualization) : 컴퓨터 내 특정 자원만을 추상화     (가상의) 메인 메모리 : 가상 메모리 (Virtual Memory)   (가상의) 저장 장치 : 클라우드 (Cloud)   (가상의) 그래픽 카드 : vGPU   (가상의) 네트워크 : 가상 사설 네트워크 (Virtual Personal Network)   플랫폼 가상화 (Platform Virtualization) : 여러 개의 프로세스을 구동할 수 있는 플랫폼을 추상화     에뮬레이션 (Emulation) : 다른 컴퓨터 프로세서를 위해 쓰인 운영체제와 응용 프로그램을 실행   하드웨어 수준 가상화 (H/W-level Virtualization) : 하드웨어 플랫폼 위의 하이퍼바이저를 통해 가상 머신을 관리함        운영체제 수준 가상화 (O/S-level Virtualization) : 운영체제의 커널이 각각의 격리된 프로세스를 동작시킴            에뮬레이터 (Emulator) : 모든 하드웨어 자원의 동작을 소프트웨어로 대체             애뮬레이터 안의 응용 프로그램은 물리 하드웨어가 아닌 인터프리터 프로그램을 통해 실행 (JVM)                    인터프리터 프로그램은 가상 머신에서 명령을 수행할 때마다 물리 CPU가 처리할 바이너리 코드 갱신           물리 CPU는 에뮬레이터를 실행하기 위한 바이너리 코드를 해석해 이를 대신 실행                       장점 : 아키텍쳐가 전혀 다른 하드웨어 역시 가상화할 수 있음 (vs 하이퍼바이저 : 가상화할 수 없음)       단점 : 물리 CPU 내에서 직접 실행할 때보다 비효율적임                하이퍼바이저 (Hypervisor) : 다수의 가상 머신을 생성, 실행, 제어하는 논리적 플랫폼으로써의 프로세스             하이퍼바이저 안의 응용 프로그램은 물리 하드웨어를 하이퍼바이저에 의해 제한적으로 사용                하드웨어 가상 머신 (H/W Virtual Machine) : 하이퍼바이저에 의해 생성된 가상 환경                        Type 1. 호스팅 (Hosting) : 하이퍼바이저가 일반 프로그램과 같이 운영체제의 소프트웨어 계층에서 실행                     장점 : 가상의 하드웨어를 구동하기에 호스트 운영 체제에 큰 제약이 없음           단점 : 호스트 위에 게스트를 구동하는 방식이기에 비교적 큰 오버헤드 가짐 / GPU Passthrough 미지원                                Type 2. 네이티브 (Native) : 하이퍼바이저를 하드웨어에 직접 임베디드되어 실행                     장점 : 별도의 호스트가 없어 오버헤드가 적음 / 하드웨어를 직접 제어하기에 효율적인 자원 사용 가능           단점 : 자체적인 가상 머신에 대한 관리 기능이 없기에, 이를 위한 별도의 컴퓨터나 콘솔이 필요                        전가상화 (Full-Virtualization) : 하이퍼바이저에서 명령을 번역                             게스트가 요청한 명령은 하이퍼바이저가 실행한 관리용 가상 머신 DOM을 통해 하드웨어에 접근               하이퍼바이저가 각 가상 머신들의 모든 명령을 번역하여 실행하고, 이에 맞게 자원을 할당해야 함                                                반가상화 (Para-Virtualization) : 게스트 가상 머신에서 명령을 번역                             게스트 가상 머신이 하이퍼 콜 (Hyper Call)을 통해 하이퍼바이저에 명령을 직접 요청               게스트 가상 머신의 운영 체제가 하이퍼 콜을 요청할 수 있게 커널을 수정해야 함                                                   컨테이너 (Container) : 소프트웨어 패키지 (Software Package)의 추상화     컨테이너는 프로세스가 동작하는 격리된 사용자 공간 인스턴스            하나의 응용 프로그램과 그 응용 프로그램의 동작을 위한 라이브러리로 구성           운영체제의 커널은 여러 개의 격리된 컨테이너를 갖추어 각각의 개별적인 서버처럼 동작시킴           컨테이너를 사용하는 이유?                가상머신보다 공간을 적게 차지하며, 재가동성 또한 가상머신보다 좋다.         어플리케이선과 동일한 환경 세트로 개발되기에, 테스트에서 프로덕션까지의 이식성 및 일관성에 용이하다.         동적으로 리소스를 사용할 수 있어, 별도의 리소스를 할당할 필요가 없다.         서버의 밀도를 늪일 수 있다. 즉, 서버 내의 리소스를 과다하게 사용하지 않는 선에서 최적화가 가능하다.         하나의 커널에서 동작하기에, 업데이트 및 패치 작업 등을 한번만 수행하면 모든 컨테이너에 적용된다.                          리눅스 컨테이너 (Linux Container) : 리눅스에서 제공하는 운영체제 레벨의 컨테이너 기술             커널 레벨의 격리된 (isolated) 공간만 제공할 뿐, 개발 및 서버 운영에 필요한 부가 기능 부족              운영체제 A에만 가능한 a, 운영체제 B에만 가능한 b, 운영체제 C에만 가능한 c을 동시에 실행한다고 가정한다면,         에뮬레이션 : 응용 프로그램 ×3 ⊂ 에뮬레이트 운영체제 ×3 ⊂ 에뮬레이터 ×3 ⊂ 호스트 운영체제 ⊂ 하드웨어     Type 1. 호스팅 : 응용 프로그램 ×3 ⊂ 게스트 운영체제 ×3 ⊂ 하이퍼바이저 ⊂ 호스트 운영체제 ⊂ 하드웨어     Type 2. 네이티브 &gt; 전가상화 : 응용 프로그램 ×3 ⊂ 게스트 운영체제 ×3 ⊂ DOM ⊂ 하이퍼바이저 ⊂ 하드웨어     Type 2. 네이티브 &gt; 반가상화 : 응용 프로그램 ×3 ⊂ 수정된 게스트 운영체제 ×3 ⊂ 하이퍼바이저 ⊂ 하드웨어     운영체제 수준 가상화 : 컨테이너 프로세스 ×3 ⊂ 컨테이너 관리 소프트웨어 ⊂ 운영체제 ⊂ 하드웨어         Q. MacOS에서 도커로 윈도우 컨테이너를 실행하는 경우엔? : 응용 프로그램을 실행할 때 (O) 운영 체제를 실행할 때 (X)            윈도우 컨테이너 ⊂ 가상 머신 (호스팅) ⊂ 컨테이너 관리 소프트웨어 ⊂ 운영체제 ⊂ 하드웨어          ","categories": [],
        "tags": ["Docker"],
        "url": "/docker1/",
        "teaser": null
      },{
        "title": "[Github Pages] 1. 개발자에게 개발 블로그는 왜 필요한가요?",
        "excerpt":"   내가 아직 취업 시장에 발도 담구지 않은 대학생인데 내가 개발 블로그의 필요성에 대해 논하는 것이 의미가 있는 걸까? 라는 의문이 들어 작년에 작성한 글에서는 이 부분을 짚어보지 않았다. 하지만 이 부분을 뺀 채로 블로그를 운영하다보니, 처음에 내가 가졌었던 생각이나 느낌이 희석되면서, 여러 가지를 이유로 들며 블로그 운영을 게을리한 것 같다. 그래서 지난 1년간 내가 작성한 내용을 다시 정리하기 앞서, 이 부분에 대해 이야기하고자 한다.    1. 블로그에 글을 쓰는 과정 또한 하나의 공부가 될 수 있다.  사실 글을 쓰는 과정은 엄청나게 귀찮다. 글을 쓰기 위한 소재도 미리 준비해야 하고, 그 소재에 대해 모르는 부분을 공부해야 하고, 내가 잘못된 내용을 적는 게 아닌지 검토하는 과정 또한 거쳐야 하고… 하지만 내가 이전에 공부하거나 경함한 내용을 자세하고 정확히 설명하기 위해 노력하면서, 그 내용에 대한 나의 이해도가 올라가는 것 같다. 이전에 블로그에 글을 쓰기 전의 나는 수업 끝나면 다시 책을 펴보지 않았지만, 지금은 블로그에 글을 쓰기 위해서라도 최대한 기록을 남기려고 노력한다. 이러면서 내가 단순히 개념으로 머릿속에 집어넣은 내용을 블로그의 문장이나 예시로 설명하면서, 내용을 이해하는 것을 넘어서 개념을 응용하는 능력 또한 증진되는 것 같다.       글을 쓰는 것과 같이 누군가에게 무언가를 설명하려고 노력하는 행위를 나만 성장하는 데에 있어 도움이 된다고 느낀 건 아닌지, 실용주의 프로그래머라는 책에서는 프로그래머가 고무 오리 인형에게 코드 한 줄씩 설명하는 고무 오리 디버깅 (rubber duck debugging)으로 무언가를 설명해본 경험의 중요성을 강조한다. 이처럼 무언가를 설명해보는 경험이 계속 축적되다보면, 나중엔 무엇을 배우든간에 그것을 어떻게 설명해볼지에 대해 미리 생각해보게 될 것이다.    그리고 당연하지만, 글은 하나의 기록이고 그 자체로 나의 history가 된다. 자신이 공부하고 경험한 것을 기록하는 것은, 당연하지만 내가 기억하는 것보다 더 오래 보존된다. 나는 공부를 하거나 이런저런 자료를 참고한 것을 모으는 방법에 대해 늘 고민하곤 했는데 (예를 들면 즐겨찾기에 등록하는 것이나 PDF를 저장하는 것. 2가지 모두 단점이 명확해 중간에 그만두었다), 역시 코드의 주석처럼 글을 쓸 때 바로바로 참고한 내용을 링크를 걸어주는 방법이 제일 즉각적이고 직관적인 것 같다. 또한 만약 생각이나 회고을 적어둔 경우에는 내가 이런 생각을 했구나, 하면서 나중에 참고하기도 좋다.   2. 블로그를 운영하는 것이 성장의 동기가 될 수 있다.  나는 어렸을 때부터 무언가를 수집하는 것을 좋아했다. 초등학교 때는 TCG 게임의 카드들을 수집해 컬렉터 앨범을 만드는 것을 좋아했고, 중학교 때에는 코인 홀더에 담을 프루프를 사기 위해 용돈을 모아본 적도 있다. 블로그에 글을 쓰는 것 또한 내가 인터넷이나 서적 곳곳에 퍼져 있는 지식들을 수집해 하나의 모음집을 만든다고 느꼈기에 처음 개설하였을 때부터 블로그를 운영하는 데에 애착이 갔다.       그래서 나는 Blog-driven, 즉 블로그를 운영하기 위해 공부하고 경험하면서 나 또한 성장한다는 개념에 대해 긍정적으로 생각한다. 대다수의 사람들이 보통 블로그에 글을 쓰면서 Blog-driven이 이루어진다고 생각하는데, 나는 Blog-driven이 더 포괄적인 개념이라고 생각한다. 블로그를 계속해서 살아있는 상태로 유지하려면 단순히 블로그에 글을 쓰는 것만이 아닌, 블로그를 개선하고 유지보수하는 과정 또한 필요하다. 지난 1년간 블로그를 운영하면서 알게 모르게 시행착오를 거친 부분이 꽤 되는데 웹 개발을 공부하면서 이를 블로그에 대입해 생각해보기도 하고, 블로그에 적용시켜볼 계획도 세우기도 하는 식으로 앞으로 나아가는 데에 큰 도움이 되었던 것 같다.    3. 운영하는 블로그가 개발자에게 새로운 기회를 줄 수 있다.  내가 이번에 대학교 4학년이 되면서 느낀 점이 있다면, 나를 포장하고 홍보하는 것 또한 정말 중요하다는 것이다. 수능은 모든 학생을 일렬로 세우고 점수로 평가하지만, 사회에는 어떤 절대적인 기준이 존재하지 않으므로 사람들이 나를 평가할 수 있는 input data를 내가 스스로 가공해 제공할 필요성이 있다. 특히 개발자는 다른 직업보다 정보를 활용하는 능력이 뛰어나다보니, Github 프로필을 만들거나 포트폴리오 사이트를 만드는 것과 같이 나에 대한 정보를 공유하는 것 또한 매우 활발하다.       요즘 IT 기업들이 지원자의 개발 블로그나 Github의 주소를 요구하는 것 또한 그런 맥락일 것이다. 기업 입장에서는 모든 점에서 뛰어난 인재를 채용하고자 하겠지만, 그것은 매우 소수이다. 그래서 기업은 지원자의 잠재력 또한 확인해 평가하고자 노력한다. 그리고 이런 부분은 개발과 직접적으로 관련되어 있지만 단순한 결과물의 집합체인 이력서나 포트폴리오보다는, 성장하는 데에 있어 중요한 가치를 엿볼 수 있는 개발 블로그나 Github에 잘 들어나는 것 같다.      Reference         코드쓰는사림 님이 작성하신, 개발자가 블로그를 운영해야 할 이유     productuidev 님이 작성하신, 개발자 취업준비 (포트폴리오/블로그)     ","categories": [],
        "tags": ["Github Pages"],
        "url": "/blog1/",
        "teaser": null
      },{
        "title": "[Github Pages] 2. 개발 블로그는 어디에 만들어야 하나요?",
        "excerpt":"   글을 시작하기 앞서 말할 부분이 있다. 이번 포스트의 내용은 나의 주관적인 판단이 들어간 서술이 많다. 나야 보시다시피 Github Pages를 사용하지만 다른 사람들은 여러 이유로 다양한 플랫폼을 사용할 것이고, 그 부분을 지적하거나 문제시하는 게 아님을 분명히 밝히고 싶다. 이 글은 어디까지나 개발 블로그로 사용되는 여러 플랫폼에 대해 이야기해보는 과정을 통해 개발 블로그를 처음 만드는 개발자들이 이런 부분을 고려했으면 좋겠다, 는 취지로 작성된 것이다.    1. 네이버 블로그     한때는 블로그, 하면 네이버? 라고 할 만큼 국내에서 가장 많이 쓰였던 블로그 플랫폼이다. 나도 개발 관련은 아니지만 작년까지 네이버 블로그를 운영했었다. 그런 점에서 가지는 네이버 블로그의 장점은 (국내 한정) 보편성이다. 보편적으로 쓰이는 만큼 사용자 수가 많고, 대다수가 한번씩은 네이버 블로그에 글 정도는 올려보게 되는 것이다. 그리고 이전의 올드한 디자인도 개선된 편이고 카테고리 사용도 간편하다. (이번에 새로 도입된 웹 에디터는 좀 불편했다.)    하지만, 네이버 블로그의 가장 큰 문제는 역시 구글에서 검색했을 때 노출이 잘 되지 않는다는 것이다. 사실상 이 문제가 다른 모든 장점을 덮고도 남는다고 무방하다. 네이버라는 하나의 생태계에서 자체적으로 생산되는 컨텐츠를 검색할 수 있다는 것이 네이버 검색이 우리나라에서 널리 쓰이는 이유이겠지만, 개발자들 대다수가 구글을 통해 검색하는 만큼 다른 개발자들에게 내 글을 노출시키기 어렵다. (물론 블로그에 글을 올리는 목적이 조회수는 아니지만 내 글을 읽어주는 독자가 있다는 것, 그것이 적어도 내 의욕을 좌지우지하는 것 같다.)    2. 티스토리        Example         이동욱 님이 운영하시는, 기억보단 기록을      2006년에 창립되어 네이버처럼 국내에서 보편적으로 많이 쓰이는 블로그 플랫폼이다. 옛날엔 초대장 시스템이 있어서 사용자들의 접근성이 다소 떨어졌는데, 이게 사라지고 나서는 많이들 사용하는 것 같다. 예전에는 다음이 운영했는데, 다음이랑 카카오가 합병된 이후로는 카카오가 운영중인 것 같다.    개발자의 시선에서는 코드 삽입도 지원하고, 플러그인도 다양해 커스터마이징도 가능하고, 구글 노출도 되고, 거기다가 구글 애드센스도 달 수 있고… 정말 안 쓸 이유가 없다. 그렇기에 정말 많은 개발 블로그들이 개설되어 있고, 나 역시도 구글링할 때에 제일 많이 들어가는 플랫폼 중 하나이다. 그래서 초심자가 가장 무난하게 개발 블로그를 시작한다면, 티스토리에서 할 것을 권하고 싶다.    아, 생각해보니 티스토리가 이런 팔방미인이 될 수 있었는지를, (TMI지만) 간략하게나마 적어두어야 할 것 같다. 티스토리가 등장하는 2000년대 중반은 막 우리나라에서 블로그라는 개념이 퍼져나가는 태동기였다. 그때는 상술한 네이버 블로그나 지금은 사라진 다음 블로그처럼 IT 기업들이 운영하는 서비스형 블로그들이 주를 이루었는데, 블로그를 정말 자유롭게 이용하기엔 회사의 약관이나 운영방침과 같은 제약이 있어 차질이 생기곤 했다. (카카오가 운영하는 티스토리 또한 이 문제에 자유롭지는 않다.)    그래서 정재훈 씨가 처음 개발하고, 이후에는 태터앤컴퍼니 (TNC)에서 외국에 존재하던 설치형 블로그를 현지화해 출시한 프로그램이 태터툴즈이었다. 태터툴즈는 기존의 설치형 블로그의 장점을 유지하면서, 한국어에 최적화된 점에서 굉장히 주목을 받았고, 그 TNC가 다음과 합작해 만든 블로그 서비스가 바로 티스토리이다. 이런 알련의 과정 속에서 탄생한 티스토리는 설치형 블로그와 서비스형 블로그의 장점이 적절히 혼합되어 있다.    참고로 TNC는 2008년 국내 최초로 구글에 인수되었고 (!), 태터툴즈는 태터툴즈 사용자 커뮤니티였던 태터네트워크재단 (TNF)에서 개발을 전담해 텍스트큐브 (TextCube)로 리브랜딩되어 현재도 운영중…이면 좋겠지만, 정식 버전은 2014년 2월에 나온 1.10.10에서 멈춘 것 같고 베타 버전도 2.0 베타 3이 마지막인 것 같다. (텍스트큐브 Github)    3. 브런치        Example         옛날개발자 님이 운영하시는, 에디의 기술블로그      브런치는 2015년에 카카오가 글쓰기에 최적화된 플랫폼을 만든다는 야심찬 목표를 갖고 오픈한 블로그 플랫폼이다. 이곳에 글을 올리려면 작가 신청을 하고 에디터팀의 승인 심사에 합격해야 한다고 한다. 그래서 브런치에서 개발 블로그를 몇개 보긴 했는데도, 솔직히 난 소설 글쓰기 플랫폼으로 알고 있었다…    하술할 미디엄을 어느 정도 벤치마킹한 것으로 보이는데, 미디엄과 달리 코드 삽입이 안되서 이미지로 캡쳐해야 한다는 점이 너무 아쉽다. 디자인이랑 폰트가 워낙 깔끔해서 글쓰기엔 특화된 느낌은 확실히 강한데, 개발 블로그로 사용하기에는 한계점이 명확해 보인다.   4. 미디엄        Example         Moon 님이 운영하시는, medium     박상권 님이 운영하시는, medium      미디엄은 2012년 에반 윌리엄스가 만든 소셜 네트워크 서비스이다. 플랫폼을 처음 보았을 때에는 트위터나 링크드인과 같은 소셜 네트워크 서비스의 느낌이 강해 보였는데, 글을 작성하려 할 때 나오는 메모장 화면이 직관적이라 굉장히 좋았다. (미디엄이 글 쓸 때 나오는 한글 폰트가 구리다는 얘기가 많은데, 확장 프로그램 깔면 해결되는 부분이라 생각해 일단 나는 고려하지 않았다.)    그런데 내가 안쓰는 이유는… 사실 처음 블로그를 만들 때 미디엄에 대해 몰랐다! 원래부터 국내 사용자 수가 적다보니 미디엄을 개발 블로그로 쓰는 분들은 더 적은 거 같다. 그리고 카테고리랑 검색 기능이 없으니, 앞서도 얘기했지만 SNS 같은 느낌이 계속 드는 것 같아서 좀 손이 잘 가지 않는다.   5. Notion        Example         younho9 님이 운영하시는, notion      나는 옛날부터 노트에 무언가를 적는 것을 선호해서 스마트폰을 산 뒤로 애플 메모, 네이버 메모, 마이크로스프트 원노트, 에버노트 순으로 메모 앱을 사용했는데 뭔가 아쉬운 점이 한두 개씩은 있엇다. 그런데 노션을 2019년즘에 처음 사용하고 나서는 너무 만족해서 쭈욱 사용하고 있다.    단점을 말하기 앞서… 확실히 짚고 가야할 것이 있다. 노션은 블로그가 아닌 메모장이다. 그런데 메모장을 블로그로 사용하려면 그게 잘 될까? 이것저것 템플릿을 잘 가져와 쓴다고 해도, 메모장이라는 근본적인 한계가 명확하다고 생각한다. 다음은 내가 직접 써보면서 느낀 단점들이다.      페이지 주소가 직관적이지 않고, 페이지 제목이 바뀌면 새로운 주소를 가지게 되어 글을 다시 공유해야 한다.   하나의 페이지이기 때문에 카테고리, 글 검색, 댓글 기능이 부재되어 있다.   페이지가 무거우면 페이지를 불러오는 그 로딩 과정이 매우 길다.   그러면 노션 블로그를 호스팅하면 되지 않을까? 할텐데, 도메인과 호스팅 비용이 상당히 든다. 당장 무료로 쓸 수 있는 옵션이 이렇게 많은데, 노션이 좋다고 계속해서 돈을 지출하는 것은 좀 과하지 않을까?   6. 벨로그     벨로그는 2018년 velopert 님이 개설한 개발자에 특화된 블로그 서비스이다. 유저 수가 소수였던 초창기와 달리, 지금은 국내 많은 개발자들이 유입되면서 개발자 생태계가 잘 구축되어 있고, 올라오는 정보의 양과 질 모두 좋은 편이다. 또한 코드 삽입, 마크다운 에디터 등 개발자에 특화된 요소들이 눈에 띄는 요소이다. 모두 같은 디자인이고 커스터마이징할 수 있는 요소가 없다는 부분이 단점이긴 하지만, 앞서 말한 티스트리처럼 초심자가 개발 블로그를 처음으로 만든다고 한다면 벨로그가 가장 이상적이라 생각한다.    7. 워드프레스 블로그     상술한 티스토리의 TMI 파트에도 잠깐 등장한 워드프레스는 2003년 출시된 오픈소스 기반 CMS이다. 전세계에 있는 정말 많은 사이트나 블로그들이 워드프레스를 기반으로 되어 있고, 다양한 플러그인과 테마 또한 존재한다. 그래서 2018년에 네이버 블로그에서 워드프레스 블로그로 이전을 시도한 적이 있었는데… 결과는 실패였다.    그때 실패한 가장 큰 이유는 그때 군생활이여서 무언가를 공부할 여건이 도저히 되지 않았다는 것이었다. 워드프레스를 처음 접했을 때 생각보다 시간이 걸리고 이에 대해 공부할 부분도 꽤 된다. 그리고 처음에 플러그인을 게임 애드온처럼 이것저것 설치했는데 버전 충돌이 생겨서, 다시 제거하고 하나씩 학습해보고… 거기다가 PHP나 자바스크립트에 대한 공부 또한 필수적이다. 이런 것을 개발자들은 학습곡선 (Learning Curve)이 계속 길어진다고 표현하던데… 정말 맞는 말이라고 생각한다.   8. Github Pages        Example         한재엽 님이 운영하시는, JBEE.io     이종립 님이 운영하시는, 기억 보조용 위키      Github Blog라는 하나의 서비스가 존재하는 건 아니고, Github가 제공하는 Github Pages를 이용해 Github 저장소에 블로그나 웹 사이트 같은 웹 서비스를 호스팅하는 방식이다. 아무래도 지금 내가 사용하고 있는 거기도 하고 지난 1년간 공부하고 경험한 것도 있기에 이 부분을 조금 상세히 언급해보고자 한다.      긍정적인 점            커스터마이징의 자유도가 엄청나게 높다. 나처럼 Github Pages용 오픈 소스 테마를 이용해도 되고 아예 처음부터 설계해 만드는 것 또한 가능하다. 구글 검색에 내 블로그를 노출시킬 수도 있고, 구글 애드센스를 통해 광고를 달아줄 수도 있다. 요약하면, 개발자가 가지고 놀기에 정말 좋다!       Github에 저장소로 올라가는 방식으므로 Github와 연동이 된다. 로컬에서 블로그를 쉽게 편집하고 관리할 수 있으며, commit과 push로 글을 등록하면 된다. Github 저장소에 백업이 되어 있기 때문에 (당연하게도) 이를 원격지에서 다운받아 사용할 수도 있고, 필요한 경우 롤백하는 것도 가능하다.       마크다운 형식으로 작성하는 것을 지원하고, 코드 블룩이나 인용 블록 또한 지원한다. 게시글 하나하나가 .md 파일이라 나중에 플랫폼을 이전한다 하더라도 이를 다시 활용하는 것 또한 가능하다.              복합적인 점            워드프레스 블로그만큼은 아니지만, 다른 것들에 비해 진입장벽이 존재한다. 처음에 웹 사이트의 소스 코드를 올리거나 수정하는 작업이 필요하므로 최소한 git이랑 markdown을 어떻게 사용하는지는 알아야 한다. 블로그를 이것저것 건드려보려고 한다면 백엔드 관련 지식이 요구되고, 커스터마이징을 해보려면 간단한 프론트엔드 관련 지식 또한 필요해진다. 물론 웹 개발자를 지망한다면 이런 일련의 과정을 한번 하는 것도 도움이 된다.       Github 저장소에 올라가는 방식이므로 저장소 내의 소스 코드가 모두 공개된다. 블로그를 노출시키고 싶지만 블로그 내부까지 노출시키고 싶지 않는다면, 유료 걔정으로 전환해서 비공개로 전환해야 한다.       하나의 Github 저장소는 용량과 트래픽에 제한이 존재한다. (1GB의 최대 용량, 월 100GB의 트래픽 제한) 제한을 넘어서 사용하려면 Cloudflare과 같은 CDN을 추가로 사용해야 한다. 일단은 한도 내에서만 쓰면 무료인 것은 장점이지만, 한도를 넘어버린다면 돈을 써야하니 용량이 있는 파일을 올리는 것과 같은 경우에 주의할 필요가 있다.              부정적인 점            정적 페이지로 빌드한는 것만 지원한다. 그래서 댓글 기능을 추가할 때 외부 데이터베이스와 연동이 되지 않아 이를 위한 플러그인을 별도로 설치해야 한다. (Github가 소스 관리를 위한 서비스이니… 동적 호스팅 서비스는 AWS와 같은 클라우드 벤더 등을 사용하자.)       벨로그처럼 작성하는 문서 서식을 바로 렌더링해서 볼 수 없다. 프리뷰 플러그인을 사용한다 치더라도, 플러그인으로 형성된 화면과 렌더링된 화면이 일치하지 않아 결국엔 플러그인을 잘 안쓰게 된다.       글을 쓸 때 표나 이미지를 넣는 게 불편하다. 나 같은 경우에는 html과 css를 사용해 넣는데, 해당 문법을 알아도 표를 일일이 만드는 것은 굉장히 귀찮다. 이미지 같은 경우에는 외부 사이트에 업로드해 이를 호스팅하는데 그것 또한 좀 번거로운 작업이다.              나는 Github Pages 블로그를 운영하는 것은 장단점이 매우 명확하고, 개개인마다의 호불호가 엄청 갈릴 수 밖에 없다고 생각한다. 실제로 Github Pages 블로그를 운영하시다가 다른 블로그 플랫폼으로 이주하시는 분들도 많이 보았고 나 또한 블로그를 개설하면서, 그리고 개설된 블로그를 운영하면서도 이주할지말지에 대해 많이 고민했었다.     그래도 내가 Github Pages 블로그를 운영하는 데에는 git을 이용해 블로그를 관리할 수 있다는 것과 블로그 운영을 통해 웹 개발의 전반적인 과정을 학습해볼 수 있다는 점이 가장 큰 이유인 것 같다. Github Pages 블로그를 개설할 때에는, 정말 아무것도 모르는 감자 (…)라서 많이 헤맸다. 그래서 처음에는 블로그와 연동되는 git에 대해 공부하고자 Do it! 지옥에서 온 문서 관리자 깃 &amp; 깃허브 입문이라는 도서를 구매해서 공부해보고, 그 다음에는 블로그를 커스터마이징해보려고 Do it! HTML+CSS+자바스크립트 웹 표준의 정석이라는 도서를 구매해서 공부해보고 이를 최대한 적용해보는 식으로 실습하였다. 이렇게 블로그를 성장시키려고 노력하는 과정 속에서 나 또한 많이 성장할 수 있었고, 앞으로도 이런 blog-driven이 잘 이루어졌으면 하는 것이 내 바램이다.      Reference         productuidev 님이 작성하신, 개발자 취업준비 (포트폴리오/블로그)     ","categories": [],
        "tags": ["Github Pages"],
        "url": "/blog2/",
        "teaser": null
      },{
        "title": "[Github Pages] 3. Github Pages 블로그 소개",
        "excerpt":"   사실 이전 포스트에서 Github Pages에 대한 내용이 있어 좀 중복되는 느낌이 들 수도 있다. 하지만, 이 포스트에서는 Github Pages의 원리를 짚어보고자 작성한 것이니 혹시 모르는 사람들은 한번 읽어보자.    Github Pages 블로그란?      정적 웹사이트 생성기 (SSG; Static Site Generator)   많은 사람들이 Github Pages로 블로그를 사용하고 있어 이를 블로그 서비스로 인식하기 쉽지만, 사실 Github Pages의 실체는! 바로 Github에서 제공하는 정적 웹 사이트 호스팅 서비스이다. 그리고 정적 웹 사이트 호스팅 서비스를 가능하게 하는 것이 바로 SSG란 것이다.    SSG로 생성된 사이트는 모든 웹 페이지를 미리 생성하고, 방문자로부터 요청이 들어오면 미리 만든 웹 페이지를 그대로 응답해준다. 그러므로 서버와 클라이언트 모두 렌더링을 위한 작업이 거의 없기 때문에, SSG로 생성된 웹 사이트는 속도가 매우 빠른 장점을 가진다. 그리고 SSG로 생성된 사이트는 미리 만들어놓은 수많은 웹 페이지로 이루어져 있는 구조라 검색엔진 최적화 (SEO; Search Engine Optimization)가 뛰어나 검색엔진이 사이트를 크롤링하는 데에 적합하다.    그러나 빌드할 때마다 모든 웹 페이지를 생성하는 작업을 매번 하다보니, 컨텐츠를 자주 업데이트하는 웹 사이트나 규모가 커 빌드 시간이 오래 걸리는 웹 사이트에서는 큰 비효율성이 발생해 SSG보다는 다른 렌더링 기술을 사용한다. 그래서 SSG는 개인 블로그와 같이 컨텐츠의 변경이 자주 일어나지 않은, 소규모 웹 사이트를 제작할 때 많이 쓰이는 기술이다. (SSG 외에도 SPA, SSR과 같은 렌더링 기술이 있는데, 달레 님께서 SPA와 SSG, 그리고 SSR이라는 글에서 잘 정리해주셨으니 참고하길 바란다.)    지금 현재 내가 사용하고 있는 Github Pages 테마인 Minimal Mistakes는 Jekyll을 정적 웹사이트 생성기로 사용해 웹 사이트를 정적으로 생성한다. Jekyll 외에도 Hexo, Hugo와 같은 여러 정적 웹사이트 생성기들이 존재하는데, 이들을 간단하게 비교해보자.      Jekyll            Ruby 기반       가장 많이 쓰이고, 한글 래퍼런스 많음       Github Pages에서 공식으로 지원 : push한 글들이 별도의 빌드 과정 없이 알아서 Publish       글이 많아질수록 전체 빌드 속도가 느려짐              Hexo            Node.js (javascript) 기반       (javascript를 써서 그런지) 한글 래퍼런스 많음       Hexo로 블로그를 만들 때 참고할 만한 글              Hugo            Golang 기반       런타임에 다른 의존성이 필요하지 않아, 빌드 과정을 포함해도 빌드 속도가 빠른 편       한글 래퍼런스는 상대적으로 적음       Hugo로 블로그를 만들 때 참고할 만한 글              지킬 (Jekyll)      사실 SSG 중에 Jekyll이 좋은 거 같아 골랐다기보단, Minimal Mistakes 테마가 내 마음에 들어서 설치했는데 구글링해보니 다들 Jekyll을 쓰더라…의 흐름으로 쓰게 된 거고, Jekyll 말고도 다른 SSG가 있는 것을 알게 된 이후에도 어차피 다 같은 SSG인데 Jekyll 말고 굳이 다른 거를 배워서 쓸 필요성을 못 느껴서 (물론 Jekyll이 문제가 많다고 느끼면 다른 SSG를 사용할지에 대해 고민해봐야 할 것이다.) Jekyll을 계속 사용하고 있긴 하다. 일단 Jekyll이 어떤 방식으로 동작하는지 정리해보겠다. (사실 SSG와 동일한 원리인데, 이를 구체화한 것으로 생각하면 된다.)    Jekyll은 동적 웹 사이트 (Dynamic Web Site)과 동일하게, 레이아웃에 해당하는 templates과 컨텐츠에 해당하는 contents를 분리해 저장한다. (이때 Jekyll에서 templates을 작성할 때 사용하는 언어가 Liquid이고, contents를 작성할 때 사용하는 언어가 markdown이다.) 하지만 동적 사이트와 달리, Jekyll은 templates와 contents을 합친 HTML 문서를 미리 빌드해 저장하고, 방문자가 요청을 보내면 정적 컨텐츠에 해당하는 HTML 문서를 전송한다.    그래서 Jekyll은 웹 사이트를 운영하기 위한 HTML 관련 지식을 몰라도, .md 파일로 문서를 작성하면 HTML 파일로 이를 변환해주는 작업을 해주며 변환된 결과물을 토대로 웹 사이트를 구축해서 서비스해준다.   깃허브 페이지 (Github Pages)   상술하였듯 Github Pages는 Github에서 제공하는 정적 사이트 호스팅 서비스로, 무료 계정에 한해 하나의 Github Pages를 무료로 제공한다. Github Pages는 연동된 Github 저장소에서 HTML, CSS, JavaScript와 같은 정적 컨텐츠를 가져와 그대로 배포하는 방식으로 작동한다. 만약 Github 저장소가 Jekyll 디렉토리의 형태로 존재한다면, Github Pages는 해당 저장소가 Jekyll로 작성된 것임을 알고 이를 Jekyll로 빌드해 배포한다.       Reference         SW developer 님이 작성하신, GitHub Pages 블로그 따라하기     Wheel 님이 작성하신, 지킬 (Jekyll)     ","categories": [],
        "tags": ["Github Pages"],
        "url": "/blog3/",
        "teaser": null
      },{
        "title": "[Github Pages] 4. Github Pages 블로그 개설",
        "excerpt":"   이 내용은 작년 9월 말부터 작성한 Minimal Mistakes으로 Github Blog 만들기’의 내용 일부분을 재구성한 것이다. 해당 포스트도 완성도 있는 글이고, 처음 블로그를 설정하시는 분들 또한 도움을 얻을 것이라 생각되나… 그때쯤 작성한 글들 대부분이 너무 나열식으로 쓰였고, 출처에 대한 언급이 많이 부실해 (모르는 부분이 있어 찾으려 하면 출처가 없어서 나도 찾지 못한다…), 부족한 점들을 보완하기 위해 다시 작성되었다.  그리고 현재 작성자의 실행 환경의 OS가 MacOS임을 미리 밝혀둔다. 아마 근시일 내에는 기기를 바꿀 계획이 없으니, 동일한 OS를 사용하시는 분들은 그대로 진행해주시면 된다.    1. Ruby 설치  macOS는 Ruby가 기본적으로 설치되어 있으니, 터미널을 실행하고 다음 명령어를 입력해 Ruby의 설치 여부를 확인한다.   ruby -v // ruby X.X.X 출력 : 정상 설치 // \"zsh: command not found: ruby\" 출력 : 설치 오류   2. Jekyll 설치  터미널 창에 gem install 명령어를 입력해 Jekyll을 설치한다. 참고로 gem은 분산 패키지로, 라이브러리의 작성, 공개, 설치를 도와주는 시스템이다.   gem install jekyll   그리고 터미널 창에 다음 명령어를 입력해 Jekyll가 정상적으로 설치되었는지 확인한다.   jekyll -v // jekyll X.X.X 출력 : 정상 설치 // \"zsh: command not found: jekyll\" 출력 : 설치 오류   3. Jekyll theme 선택  이전 포스트에서 Jekyll은 레이아웃에 해당하는 templates과 컨텐츠에 해당하는 contents를 합쳐 HTML 문서로 미리 빌드해 저장하고, 이를 방문자에게 보여준다고 설명한 바 있다. 그런데 대부분의 블로거들은 레이아웃의 중요성은 알지만 이를 어떻게 구성해야할지 몰라 막막할 것이다. 그런 블로거들을 위해 존재하는 것이 Jekyll theme이다.    Jekyll theme은 다른 사람들이 미리 작업해놓은 templates으로, 많은 Jekyll theme들이 무료로 공개되어 있다. 무료 Jekyll 중에 사람들이 많이 사용하는 것이 minimal-mistakes이다. 간결하고 깔끔한 디자인과 꾸준한 업데이트, 그리고 무엇보다 엄청난 양의 한글 래퍼런스 (…)로 인해 나 역시도 minimal-mistakes을 기반으로 블로그를 개설하였기에, 앞으로 진행할 블로그 개설 역시 minimal-mistakes를 기반으로 진행한다.    먼저 minimal-mistakes Github 페이지에서 .zip 파일을 다운로드한 후 압축을 해제한다. 그리고 아래 사진을 참고하여 필요한 파일 및 디렉토리만 남기고 나머지는 삭제한다. (아, 기존에 존재하지 않는 _post와 _page 디렉토리는 추후에 사용할 예정이니 미리 생성해두자.)      4. 로컬에서 웹 호스팅  터미널 창에 다음 명령어를 입력해 Gemfile을 설치하기 위한 bundler를 사용해보자. 그러면 .jekyll-cache 폴더와 Gemfile.lock 파일이 생성된다.   gem install bundler   bundler 설치가 완료되면, 터미널 창에 다음 명령어를 입력해 Gemfile을 검사해 필요한 목록을 설치할 수 있다.   bundle install   이제 터미널 창에 다음 명령어를 입력하여 블로그를 로컬에서 호스팅해보자.   bundle exec jekyll serve   http://127.0.0.1:4000으로 접속하면 minimal-mistakes이 적용된 블로그 화면을 확인할 수 있다.   5. GitHub Pages에서 웹 호스팅   이제 Github에 (Github ID).github.io의 형식으로 원격 저장소를 생성하자. 다음은 내 블로그가 저장된 원격 저장소 이미지이다.      그리고 지금까지 정리한 내용들을 포함한 디렉터리를 github에 push하면, https://(Github ID).github.io를 주소로 하는 블로그가 생성된 것을 확인해볼 수 있다. 그리고 https://github.com/(Github ID)/(Github ID).github.io/actions에서 블로그가 빌드된 기록을 확인할 수 있다. 만약 원격 저장소에서 푸시된 내용에 대한 빌드 작업이 실패한다면, 그 내용의 배포가 진행되지 않은 것을 확인해볼 수 있다.      Reference         SW developer 님이 작성하신, GitHub Pages 블로그 따라하기     ","categories": [],
        "tags": ["Github Pages"],
        "url": "/blog4/",
        "teaser": null
      },{
        "title": "[Github Pages] 5. Github Pages 블로그 설정 & 포스트",
        "excerpt":"   솔직히 블로그 설정을 건드는 부분은 내가 아는 정보들을 그대로 나열할 수 밖에 없다고 생각한다… 그래도 내가 시행착오를 겪었던 경험을 떠올리면서 하나하나 풀어서 작성하려 하였으니, 미숙한 글이지만 남들에게 도움이 되었으면 정말 좋겠다… 그리고 Github Pages이나 Minimal Mistakes으로 처음 블로그를 운영하시는 분들의 시선에 맞춰 html, css에 대한 자세한 내용은 다른 포스트로 옮겼으니 참고해주셨으면 한다.    1. 블로그 기본 설정     위의 디렉터리에서 _config.yml이라는 파일을 열어보면 다음과 같이 구성되어 있는데, 오른쪽의 주석을 참조해서 나만의 블로그를 커스텀마이징해보자. 이걸 어떻게 적용하는지 잘 모르겠다, 싶은 사람은 내 블로그에 적용된 것을 예시로 보면서 작업해보자.   minimal_mistakes_skin    :         # 블로그의 전체적인 스킨 지정                                     # (Minimal Mistakes에서 기본적으로 제공)                                    # \"default\" \"air\", \"aqua\", \"contrast\", \"dark\"                                    # \"dirt\", \"neon\", \"mint\", \"plum\", \"sunrise\"  # Site Settings locale                   : \"ko-KR\" # 블로그에 쓰일 로컬 언어 지정 title                    :         # 메타 태그에 들어갈 블로그의 제목 지정 subtitle                 :         # 블로그의 제목 하단에 위치할 부제목 지정 name                     :         # 블로그 저자 이름 지정 description              :         # SEO 향상을 위한 meta description 태그 지정 url                      :         # 블로그 url                                     # \"https://(github ID).github.io\" repository               :         # github repository url                                    # \"https://github.com/(github ID)/(github ID).github.io\" teaser                   :         # 관련 포스트나 검색 등에 들어갈 미리보기 이미지 지정                                    # (\"assets/images/\"로 연결) logo                     :         # 블로그의 제목 옆에 들어갈 로고 이미지 지정                                    # (\"assets/images\"로 연결) masthead_title           :         # 블로그 프로필 상단에 위치할 사이트 제목 지정 breadcrumbs              : true    # 브래드크럼 사용 여부 지정 words_per_minute         : 200     # 포스트를 읽는 데 걸리는 시간을 계산히기 위한 분당 읽는 글자의 지정   2. 블로그 레이아웃 설정  이제 조금은 삭막한(?) 블로그의 레이아웃을 뜯어고칠 차례이다. 우선은 이전처럼 _config.yml 파일을 아래와 같이 자신이 원하는 대로 수정하면 된다.   ## 블로그 좌측 사이드바에 위치할 프로필 설정 author:   name             :       # 저자 이름 지정   avatar           :       # 저자 이미지 지정   bio              :       # 저자 바이오그래피 지정   location         :       # 저자 위치 지정   email            :       # 저자 이메일 지정   links:                   # 저자 관련 사이트 링크 지정     - label:               # 사이트 분류 지정       icon:                # 사이트 아이콘 지정       url:                 # 사이트 url 지정  ## 블로그 하단에 위치할 꼬리말 설정 footer:   links:                   # 블로그 관련 사이트 링크 지정     - label:               # 사이트 분류 지정       icon:                # 사이트 아이콘 지정       url:                 # 사이트 url 지정   (1) 네비게이션 바   다음은 기본 테마를 보면서 혹은 자기가 기능을 적용하면서 불편한 점들을 확인하고, 직접 테마의 요소들을 뜯어고치는 건데… 이건 사람마다 달라서 뭐라고 말을 못하겠다. 그래서 나 같은 경우에 어떤 부분이 불편했고, 그래서 수정했는지 얘기해보고자 한다. 우선은 블로그 상단의 네비게이션 바에 내가 보기에 불필요한 카테고리들이 있었다. 그래서 카테고리, 태그만 남기기 위해  _data/navigation.yml 파일을 수정하였다.  _pages 디렉토리를 보면 여기에 적용할 수 있는 여러 요소들이 있는데, 직접 입맛에 맛게 적용해보면 된다.   main:   - title: (카테고리)        # 화면에 보여질 세부 항목의 이름 지정     url: /(카테고리)/        # _pages 내에 정해진 양식 파일이나 특정 링크로 연결   (2) 블로그 너비 및 폰트 크기   그리고 블로그에 포스트를 쓸 때에 한쪽에는 VS Code를, 다른 쪽에는 로컬에서 호스팅한 블로그를 보기 위한 사파리 브라우저를 띄워 놓곤 했는데, 그때마다 기본으로 설정된 블로그 너비랑 폰트 크기가 글을 읽기에 굉장히 불편했다. 그래서 _sass/minimal_mistakes/_variables.scss 파일과 _sass/minimal_mistakes/_reset.scss 파일을 다음과 같이 수정해보았다.   // 블로그 너비 설정 /*    Grid    ========================================================================== */  $right-sidebar-width-narrow: 200px !default;    // default 200px $right-sidebar-width: 300px !default;           // default 300px $right-sidebar-width-wide: 400px !default;      // default 400px   ## 블로그 폰트 크기 설정 html {   /* apply a natural box layout model to all elements */   box-sizing: border-box;   background-color: $background-color;   font-size: 16px;                    // Default 16px;    @include breakpoint($medium) {     font-size: 16px;                  // Default 18px;   }    @include breakpoint($large) {     font-size: 16px;                  // Default 20px;   }    @include breakpoint($x-large) {     font-size: 16px;                  // Default 22px;   }    -webkit-text-size-adjust: 100%;   -ms-text-size-adjust: 100%; }   (3) 블로그 아이콘   또 블로그 주소 창에 같이 뜰 아이콘이 아무것도 안 뜨니 뭔가 내 블로그 같다는 느낌이 안들었다. 그래서 이것 또한 _includes/_head/custom.html 파일에 내가 원하는 아이콘을 넣었다.   &lt;!-- start custom head snippets --&gt;  &lt;!-- insert favicons. use https://realfavicongenerator.net/ --&gt; &lt;link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/assets/logo.ico/apple-touch-icon.png\"&gt; &lt;link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/assets/logo.ico/favicon-32x32.png\"&gt; &lt;link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/assets/logo.ico/favicon-16x16.png\"&gt; &lt;link rel=\"mask-icon\" href=\"/assets/logo.ico/safari-pinned-tab.svg\" color=\"#ffffff\"&gt; &lt;meta name=\"msapplication-TileColor\" content=\"#ffffff\"&gt; &lt;meta name=\"theme-color\" content=\"#ffffff\"&gt;   내가 수정한 것은 이정도? 인데 자잘하게 더 파고들면 커스텀마이징할 레이아웃 요소가 정말 많다. html, css, yml 파일을 건드는 것이라 그리 어렵지도 않고, 한번 배워두면 생각보다 쓸 때도 많다. 아래는 Minimal Mistakes Themes의 디렉토리 구조에 주석을 단 것인데, 커스텀마이징이 필요할 때 이를 참고하기 좋은 것 같다.   minimal-mistakes ├── _data                                 # 테마를 커스터마이징하기 위한 파일을 저장하는 디렉터리  | |                                       # (yml, yaml, json, csv, tsv 파일을 자동으로 읽어들어 site.data로 사용) | ├── navigation.yml                      # 상단 메뉴바를 커스터마이징하기 위한 파일 | └── ui-text.yml                         # 언어별로 어떤 텍스트로 표시되는지 나열하는 파일 | ├── _site                                 # 재사용되는 html 파일을 저장하는 디렉터리 (공통된 컴포넌트들 보관) | ├── search                              # 검색 엔진을 커스터마이징한 내용을 저장하는 디렉터리 | ├── analytics-providers | └── custom.html                         # 분석 플랫폼 공급자를 커스터마이징한 내용을 저장하는 파일 | ├── comments-providers | └── custom.html                         # 댓글 플랫폼 공급자를 커스터마이징한 내용을 저장하는 파일 | ├── head | └── custom.html                         # head를 커스터마이징한 내용을 저장하는 파일 | ├── footer | └── custom.html                         # footer를 커스마이징한 내용을 저장하는 파일 | ├── nav_list                            # 메뉴 상단바의 리스트에 대한 helper 파일 | ├── archive-single.html                 # 아카이브 문서에서 단일 문서를 표현하는 방법을 저장하는 파일 | ├── author-profiles.html                # author profile link애 대한 내용을 저장하는 파일 | ├── author-profile-custom-links.html    # author profile link를 커스마이징한 내용을 저장하는 파일 | ├── breadcrumbs.html                    # breadcrumbs에 대한 내용을 저장하는 파일 | ├── single-page | ├── page__taxonomy.html                 # 단일 문서에서 태그와 카테고리를 표현하는 방법을 저장하는 파일 | ├── tag-list.html                       # 단일 문서에서 태그 리스트를 표현하는 방법을 저장하는 파일 | └── category-list.html                  # 단일 문서에서 카테고리 리스트를 표현하는 방법을 저장하는 파일 ├── _posts                                # 블로그에 포스트한 md 파일을 저장하는 디렉터리 ├── _includes ├── _layouts                              # 각 문서의 디자인과 직접적으로 연결된 전체적인 레이아웃 디렉토리 ├── _sass                                 # minimal-mistakes.scss에 임포트할 수 있는 scss 파일을 저장하는 스타일시트 디렉터리 ├── assets                                # css, js, 이미지 파일을 저장하는 디렉터리 | ├── _css | ├── _images | └── _js  ├── _config.yml                           # 블로그를 구성하기 위한 기본적인 설정값을 설정하는 yml 파일 ├── Gemfile                               # 사용할 gem 플러그인 목록 ├── index.html                            # 블로그 처음 홈 페이지 └── package.json   3. 블로그 포스트 작성 및 머릿말 작성  _posts 폴더에 XXXX(YEAR)-XX(MONTH)-XX(DAY)-(NAME).md을 생성해보자. 이때 YEAR, MONTH, DAY는 포스트가 작성된 연도, 월, 일이 되고 NAME은 포스트의 경로가 된다. 그리고 파일 상단에 위치할 머릿말을 작성하기 위해 아래와 같이 ---에 둘러싸인 내용을 작성해보자.   --- title: \"[Blog] macOS에서 Minimal Mistakes로 깃허브 블로그 만들기\"  categories:     - Github.io  tag:     [HTML, JavaScript, SCSS, Ruby]  toc: true toc_sticky: true  date: 2022-09-26 lastmod: 2022-09-26 ---                              양식 이름             양식 설명                                         title             포스트 제목                               categories             포스트 카테고리                               tags             포스트 태그                               toc             우측 상단의 목차                               toc_label             목차 이름                               toc_icon             목차 아이콘                               toc_sticky             목차 고정 여부                               date             포스트 작성일                               lastmod             포스트 수정일                               author_profile             프로필 창 표시 여부                 우리가 글을 작성하는 데에 사용할 Markdown은 텍스트 기반의 마크업 (MarkUp) 언어로, 특수기호와 문자를 활용한 매우 간단한 구조의 문법을 사용해 보다 빠르게 컨텐츠를 작성할 수 있다! Github의 README.md가 대표적인 예시인데, Github Pages 역시 이를 활용해 문서를 작성하는 데에 사용한다. 마크다운 문법은 여기서 상세히 설명하고 있으니 참고하자.   4. 블로그 포스트 내에 문자 박스 양식 넣어보기  추가로 minimal-mistakes theme의 css로 설정된 스타일 요소를 class로 불러와 적용할 수 있는데, 그중 하나인 상자 양식을 활용해보자. Markdown (.md) 파일이니까 html 태그들을 쓰면 그대로 화면에 표현할 수 있다.   &lt;p class=\"notice--primary\"&gt;   &lt;strong&gt;     이 항목은 현재 작성중입니다.   &lt;/strong&gt;&lt;br&gt;     &gt; 아직 미완성된 코드나 문장 구조가 정확하지 않은 내용이 있을 수 있으니 유의하시기 바랍니다. &lt;/p&gt;  &lt;p class=\"notice--info\"&gt;   &lt;strong&gt;     이 항목은 macOS 기반으로 작성되었습니다.   &lt;/strong&gt;&lt;br&gt;     &gt; 프로그램, 단축키 설정 등이 다른 OS 환경과는 호환이 안되는 경우가 많으니 유의하시기 바랍니다. &lt;/p&gt;  &lt;p class=\"notice--danger\"&gt;   &lt;strong&gt;     이 항목은 최신의 내용을 담고 있지 않을 수 있습니다.   &lt;/strong&gt;&lt;br&gt;     &gt; 맨 아래의 항목 업데이트 날짜와 OS나 프로그램의 버전 정보를 꼭 확인해주시기 바랍니다. &lt;/p&gt;  &lt;p class=\"notice--warning\"&gt;   &lt;strong&gt;     이 항목은 검증되지 않은, 편향된, 혹은 잘못된 내용을 포함할 수 있습니다.   &lt;/strong&gt;&lt;br&gt;     &gt; 작성자 역시 공부하는 학생이기에 해당 부분을 댓글이나 이메일을 통해 지적해주신다면 정말 감사할 것 같습니다. &lt;/p&gt;                  이 항목은 현재 작성중입니다.             &gt; 아직 미완성된 코드나 문장 구조가 정확하지 않은 내용이 있을 수 있으니 유의하시기 바랍니다.                    이 항목은 macOS 기반으로 작성되었습니다.             &gt; 프로그램, 단축키 설정 등이 다른 OS 환경과는 호환이 안되는 경우가 많으니 유의하시기 바랍니다.                    이 항목은 최신의 내용을 담고 있지 않을 수 있습니다.             &gt; 맨 아래의 항목 업데이트 날짜와 OS나 프로그램의 버전 정보를 꼭 확인해주시기 바랍니다.                    이 항목은 검증되지 않은, 편향된, 혹은 잘못된 내용을 포함할 수 있습니다.             &gt; 작성자 역시 공부하는 학생이기에 해당 부분을 댓글이나 이메일을 통해 지적해주신다면 정말 감사할 것 같습니다.          Reference         Jekyll 디렉토리 구조 (번역)     ","categories": [],
        "tags": ["Github Pages"],
        "url": "/blog5/",
        "teaser": null
      },{
        "title": "[Github Pages] 6. Github Pages 블로그 기능 추가",
        "excerpt":"   이 게시물은 Github Pages 블로그, 혹은 Minimal Mistakes 테마에 없는 기능들을 추가해나간 기록들이다. html이나 css를 다룰 줄 알면 금방 할 수 있는, 혹은 다 구글링하면 나오는 내용들이긴 하지만 내가 어떻게 문제를 인식하여 어떤 과정을 거쳐 이를 해결하였는지, 에 대해 자세히 쓰고 싶었다. 그래서 이 게시물은 다른 게시물들과 달리, 내가 블로그에서 부족하다고 느낀 점들을 계속 조금씩이라도 보충해나갈 계획이다.    1. 블로그 댓글 (feat. disqus, giscus)  앞서 서술한 게시물을 보면 Github Pages는 정적 웹 사이트 호스팅 서비스라는 말이 있다. 모든 웹 페이지를 미리 생성하고, 방문자로부터 요청이 들어오면 미리 만든 웹 페이지를 그대로 응답한다는 건데, 사용자와 동적으로 정보를 주고받아야 하는 댓글 등의 기능은 불가능하다는 것이다.    그래서 처음에는 댓글 플랫폼인 disqus를 통해 이를 해결하고자 하였다. 방법은 간단한데, 사이트에 가입하고 무료 플랜을 구독한 다음에 _config.yml를 다음과 같이 수정해주기만 하면 된다.   comments:   provider               : \"disqus\" # 댓글 제공자 지정   disqus:     shortname            :          # disqus ID 지정   그런데 disqus에서 제공하는 기능인 ‘SNS로 댓글 달기’은 개발자 친화적인 기능은 아니였고, 또 나중에는 광고가 노출되기 시작했다. 그래서 대안으로 찾은 게 giscus인데, GitHub Discussions로 작동하고, 마크다운도 지원하면서 대댓글이나 반응과 같은 자잘한 기능들이 마음에 들었다.      적용하는 방법도 Github 앱을 저장소에 설치한 뒤에 html 파일에 아래의 스크립트를 넣어주기만 하면 되는데, 나 같은 경우에는 Minimal Mistakes 테마에서 _includes/social_share.html 파일에 해당 구문을 넣어 적용시켰다.   &lt;section class=\"page__share\"&gt;   &lt;script src=\"https://giscus.app/client.js\"     data-repo=\"pocj8ur4in/pocj8ur4in.github.io\"     data-repo-id=\"R_kgDOICGarA\"     data-category=\"Q&amp;A\"     data-category-id=\"DIC_kwDOICGarM4CZ65L\"     data-mapping=\"pathname\"     data-strict=\"1\"     data-reactions-enabled=\"0\"     data-emit-metadata=\"1\"     data-input-position=\"top\"     data-theme=\"dark_dimmed\"     data-lang=\"ko\"     data-loading=\"lazy\"     crossorigin=\"anonymous\"     async&gt;   &lt;/script&gt; &lt;/section&gt;   2. 블로그 Google 검색 노출 및 검색 설정  아무래도 블로그를 운영하다 보면 다른 사람들의 반응이 궁금할 때가 많은데, 아무것도 설정하지 않은 블로그는 검색되지 않는다는 사실을 깨닫고 해결책을 찾아보았다. Google Search Console에서 내 도메인을 입력한 다음에 소유권 확인을 위해 다운받은 .HTML파일을 root에 위치시키만 하면 며칠 안으로 아래와 같이 적용된다.      추가로 블로그 포스트들이 검색 엔진에 검색되는 것을 가능하도록 진행할 작업들이 있는데, 먼저 _config.yml 파일에서 아래 설정들을 true로 설정한다.   search                   : # 블로그 검색 여부 지정 search_full_content      : # 블로그의 내용 검색 여부 지정   그리고 웹 크롤링을 위해 sitemap.yml과 robots.txt 파일을 생성해 root에 위치시키면 된다.   # 모든 웹 사이트 컨텐츠에 대한 모든 웹 크롤러의 접근 허용 User-agent: * Allow: /  # 모든 웹 사이트 컨텐츠에 대한 모든 웹 크롤러의 접근 차단 User-agent: * Disallow: /  # 구글 검색 로봇만 차단하고, 다른 모든 웹 사이트 컨텐츠에 대한 모든 웹 크롤러의 접근 허용 User-agent: Googlebot Disallow: /  # 네이버 검색로봇만 차단하고, 다른 모든 웹 사이트 컨텐츠에 대한 모든 웹 크롤러의 접근 허용 User-agent: Yeti Disallow: /  Sitemap: https://pocj8ur4in.github.io/sitemap.xml   만약에 블로그의 방문자 수 통계를 보고 싶다면, Google Analytics를 가입한 후 애널리틱스 데이터 스트림을 설정하면 된다. 이때, 측정 ID를 복사한 후 _config.yml 파일을 다음과 같이 수정하면 된다.   # Analytics analytics:   provider               : \"google-gtag\"   google:     tracking_id          : \"(측정 ID)\"   ","categories": [],
        "tags": ["Github Pages"],
        "url": "/blog6/",
        "teaser": null
      },{
        "title": "[Docker] 2. Docker",
        "excerpt":"도커 (Docker) : 컨테이너 기반 가상화 (Container-based Virtualization)      Q. 도커를 쓰는 이유? : 비교적 효율적인 가상화 방식 + 통일된 개발 환경 + 배포의 동시성     Virtualization : 응용 프로그램 실행 시 운영체제 수준 가상화 방식이 성능 손실이 더 적고 빠르게 동작한다.   Development : 운영체제에 상관없이 같은 환경에서 개발할 수 있게 해준다.   Deployment : 서비스 환경과 응용 프로그램을 같이 배포할 수 있게 한다.           분산 어플리케이션을 클라우드 환경으로 이주한다고 가정하면,                IaaS : 서비스로서의 인프라                        어플리케이션을 구성하는 각 컴포넌트가 모두 가상 머신에서 독립적으로 동작             이주 과정은 쉽지만, 가상 머신의 성능을 모두 활용하지 못하며 운영비가 비쌈                             PaaS : 서비스로서의 플랫폼                        어플리케이션을 구성하는 각 컴포넌트가 클라우드 서비스 제공자의 매니지드 서비스에 종속             운영비가 저렴하고 관리가 쉬우나, 이주 과정이 복잡함                                       … 도커를 활용한다면? : 각 컴포넌트를 컨테이너로 이주하고, 쿠버네티스 등으로 전체 어플리케이션 관리 가능       공식 홈페이지에서 .dmg 파일을 다운로드 후 설치   터미널 창에 다음 명령어를 입력해 도커가 정상적으로 설치되었는지 확인   docker version // 현재 도커의 버전 확인  Client:  Cloud integration: ~  Version:           ~  API version:       ~  Go version:        ~  Server: ~  Engine:   Version:          ~   API version:      ~   Go version:       ~     Q. 클라이언트와 서버의 버전 정보가 따로 구성되어 있는 이유?         도커가 클라이언트와 서버의 역할을 각각 수행할 수 있음                리눅스 터미널에 도커 명령어를 입력하면 도커 클라이언트가 도커 서버로 명령을 전송하고 결과를 출력                  도커 컴포넌트 (Docker Component) : 도커 엔진을 중심으로 여러 컴포넌트를 조합해 구성           도커 엔진 (Docker Engine) : 도커 이미지를 생성하고 컨테이너를 관리             로컬 이미지 캐시 담당 : 새로운 이미지가 필요할 때 이미지를 다운로드하거나, 기존 이미지를 사용       Docker API을 통해 맡은 기능 수행 → 도커 명령행 인터페이스 (Docker CLI)에서 도커 API 호출                도커 레지스트리 (Docker REgistry) : 도커 이미지를 공개하고 공유             Docker 공식 레지스트리 서비스로 Docker Hub가 있음       클라우드 사업자 또한 AWS ECR, GCP Artifact Registry 등의 컨테이너 레지스트리 제공                도커 컴포즈 (Docker Compose) : 여러 컨테이너를 하나의 서비스로 정의해 컨테이너의 묶음으로 관리             여러 개의 컨테이너 구성 정보를 코드로 정의한 파일을 읽어 컨테이너를 순차적으로 생성                도커 머신 (Docker Machine) : 가상 호스트에 도커 엔진을 설치하여 호스트를 관리             여러 운영체제나 클라우드 환경에서 도커를 동일하게 실행하기 위해 도커의 실행 환경을 자동으로 생성                도커 스왐 (Docker Swarm) : 여러 도커 호스트를 클러스터화해 관리             Manger가 클러스트를 관리하거나 API를 제공하고, Node가 컨테이너를 실행           도커 명령어 (Docker Command) : docker &lt;command&gt; 형식으로 구성     리눅스 터미널에 도커 명령어를 입력하면 도커 서버에서 이에 해당되는 작업 수행   항상 root 권한으로 실행되기에 $ sudo를 앞에 붙어야 함   sudo usermod -aG docker $USER # 현재 사용자를 docker 그룹에 추가                                               docker 명령어                 명령어 형식                 명령어 설명                                                             docker search                 $ docker search [이미지]                 도커 허브에서 이미지 검색                                           docker pull                 $ docker pull [사용자명/] 이미지 [:태그]                 도커 허브에서 이미지 다운로드 사용자명을 지정해 도커 허브에서 해당 사용자가 올린 이미지을 다운로드 태그로 버전을 지정해 다운로드 (latest : 최신 버전)                                           docker images                 $ docker images                 사용 가능한 모든 이미지 목록 확인                                           docker rmi                 $ docker rmi 이미지 [:태그]                 다운로드한 이미지 삭제 태그로 버전을 지정해 다운로드 (latest : 최신 버전)                                           docker run                 $ docker run [옵션] [실행할 이미지]                 이미지를 컨테이너로 생성한 뒤 컨테이너 실행 입력받은 이미지가 현재 없다면, 해당 이미지를 도커 허브에서 다운로드 실행할 파일을 지정해 직접 실행 가능 (여기서 빠져나오면 컨테이너가 정지)                                             docker run 옵션                 옵션 설명                                                             -d                 백그라운드 모드 (detached mode)                                           -p [호스트 포트:컨테이너 포트]                 호스트와 컨테이너의 포트를 연결 (port forwarding) http://호스트 IP:호스트 포트로 컨테이너의 포트 접속                                           -v [호스트의 디렉터리]                 호스트의 디렉터리를 컨테이너의 디렉터리에 연결 (mount)                                           -e [환경변수]                 컨테이너 내에서 사용할 환경변수 설정 (environment variable)                                           --name [컨테이너 이름]                 컨테이너 이름 설정 (container name)                                           -rm                 프로세스 종료 시 컨테이너 자동으로 제거 (remove container)                                           -link [컨테이너 이름:주소]                 컨테이너와 컨테이너 연결 (link container) [주소:포트번호]로 컨테이너에 접속                                           -it                 리눅스 터미널 입력을 위한 옵션 (interactive / Pseudo-tty)                                                                      docker ps               $ docker ps [옵션]               실행중인 모든 컨테이너 목록 확인 -a 옵션으로 정지된 컨테이너까지 모두 검색                                         docker start               $ docker start [컨테이너 이름 | 컨테이너 ID]               정지된 컨테이너 재시작                                         docker stop               $ docker exec [컨테이너 이름 | 컨테이너 ID]               실행 중인 컨테이너 정지                                         docker attach               $ docker attach [컨테이너 이름 | 컨테이너 ID]               실행 중인 컨테이너에 접속                                         docker exec               $ docker exec [컨테이너 이름 | 컨테이너 ID] [명령] [매개 변수]               컨테이너 외부에서 컨테이너 내의 명령 실행                                         docker diff               $ docker diff [컨테이너 이름 | 컨테이너 ID]               컨테이너가 실행되면서 변경된 파일 목록 확인 A : 추가된 파일 C : 변경된 파일 D : 삭제된 파일                                         docker cp               $ docker cp [컨테이너 이름 | 컨테이너 ID] [:컨테이너 경로] [호스트 경로]               컨테이너의 파일을 호스트의 디렉토리로 복사                                         docker attach               $ docker attach [컨테이너 이름 | 컨테이너 ID]               실행 중인 컨테이너에 접속                                         docker rm               $ docker exec [컨테이너 이름 | 컨테이너 ID]               생성된 컨테이너 삭제                                         docker commit               $ docker commit [옵션] [컨테이너 이름 | 컨테이너 ID] [이미지 이름] [:태그]               컨테이너를 이미지 파일로 생성                                         docker build               $ docker build [옵션] [도커 파일 경로] [--tag 이미지 이름 : 이미지 태그]                도커 파일에 설정된 내용대로 도커 이미지 생성 --tag 뒤에 이미지 이름와 이미지 태그를 설정할 수 있음                                         docker history               $ docker history [이미지 이름 | 이미지 ID] [:태그]               도커 파일에 설정된 내용대로 이미지 히스토리 생성                                         docker inspect               $ docker inspect [이미지나 컨테이너 이름 | 이미지나 컨테이너 ID]               이미지나 컨테이너의 세부 정보 출력                              ","categories": [],
        "tags": ["Docker"],
        "url": "/docker2/",
        "teaser": null
      },{
        "title": "[Docker] 3. Docker Container",
        "excerpt":"도커 컨테이너 (Docker Container) : 도커에서 제공하는 컨테이너 기술      해당 부분에서 이어지는 내용입니다. 이전 내용에서는 가상화의 한 종류인 컨테이너 기술에 대해 서술하였다면, 이번에는 도커를 중심으로 하여 컨테이너에 대해 다뤄보겠습니다.    도커 컨테이너는 도커가 관리하는 독립적인 가상 리소스를 가진다.     컨테이너 안에는 어플리케이션과 그 어플리케이션의 실행 환경 (호스트명, IP 주소, 디스크 드라이브 등)이 들어있음            각 컨테이너는 독립적인 환경을 가지되, 실행되는 컴퓨터의 CPU, 메모리, 운영체제를 공유함                    격리 (isolation)와 밀집 (density)의 조건을 동시에 충족           빌드 - 공유 - 실행의 workflow으로 소프트웨어 배포를 단순화하기에 적합                                 컨테이너 내부 어플리케이션이 실행중이여야 컨테이너의 상태도 실행 중이 된다.            컨테이너가 Existed인 상태에서는 CPU 자원이나 메모리를 사용하지 않는다.           컨테이너가 종료되어도, 컨테이너는 사라지지 않고 그대로 남아있다.            나중에 다시 컨테이너를 실행하거나, 내부 파일이나 로그를 확인해볼 수 있다.       컨테이너를 백그라운드에서 계속 동작하도록 하려면, -d (--detach)           컨테이너는 기본적으로 외부 환경에 노출되지 않는다.            도커는 호스트 컴퓨터의 네트워크 계층에 끼어들어 네트워크 트래픽 중 필요한 것을 컨테이너에 전달       컨테이너의 포트를 호스트 컴퓨터에 공개하려면, --publish                    도커가 호스트 컴퓨터를 주시하다가 해당 포트로 들어오는 트래픽을 컨테이너에 전달                           도커 컨테이너 또한 별도의 환경 변수 (Environment variable)를 가질 수 있다.     호스트 운영체제의 것을 가져오는 것이 아닌, IP 주소나 호스트 이름처럼 도커로부터 부여받음   도커 이미지 (Docker Image) : 컨테이너의 실행에 필요한 모든 파일과 설정값 정보를 포함     상태값을 가지지 않음 (변하지 않는 값들을 저장) ↔ 컨테이너 : 이미지가 실행된 살태 (변하는 값들을 저장)   이미지 레이어 : 도커 이미지는 여러 Read-Only 레이어로 구성되고, 파일 추가 및 생성 시 새로운 레이어 생성            이미지 레이어는 도커 엔진의 캐시에 물리적으로 저장된 파일로, 여러 이미지와 컨테이너에서 공유함       유니온 파일 시스템 (Union File Systems)읕 통해 여러 개의 레이어를 하나의 파일 시스템으로 활용                   docker image ls에서 도커 이미지의 SIZE는 논리적 용량이지 실제로 차지하는 디스크 용량이 아니다!                 docker system df를 통해 이미지 전체 용량의 총합을 볼 수 있다.              컨테이너 레이어 : 컨테이너가 실행되면 이미지 레이어 위에 읽기-쓰기 (Read-Write) 레이어를 추가            컨테이너를 실행하면서 생성되거나 변경된 내용을 저장           이미지 경로 : URL 방식으로 관리 -&gt; 뒤에 태그 (/tag)를 붙임   Q. 도커 이미지를 쓰는 이유? : 도커 이미지와 도커 컨테이너들을 클래스나 인스턴스처럼 활용한다.     도커는 해시 값 (= 컨테이너 ID)과 임의의 이름 (= 컨테이너 이름)를 통해 컨테이너를 구분하고 이들을 환경변수로 관리    운영자가 지금까지 운영한 서버를 도커 이미지로 배포하고 도커 컨테이너에 설치한다면,    도커 파일 : 지금까지 서버를 운영한 기록   도커 이미지 (도커 파일 + 실행 시점) : 지금부터 설치된 서버가 가질 초기값   도커 컨테이너 (도커 파일 + 환경 변수) : 지금부터 설치된 서버가 운영될 장소      도커 안에서는 서버 역시 하나의 소프트웨어처럼 사용할 수 있고, 생성할 수 있는 컨테이너의 개수에도 제한이 없다.   도커 허브 (Docker Hub) : 도커 이미지를 서버에 공유하는 도커 레지스트리 서비스      도커 허브 계정을 생성한 후, 터미널을 통해 도커 허브에 접속   docker login --username pocj8ur4in Password: Login Succeeded      도커 이미지의 다운로드를 위한 이미지 참조 (Image Reference)는 네 개의 요소로 구성            이미지가 저장된 레지스트리 도메인 (기본값은 도커 허브)       이미지 작성자 계정 ID       이미지 레포지토리 ID       이미지 태그 (기본값은 latest)           docker.io/diamol/golang:latest      이미지에 새로운 이미지 참조를 부여하여, 한 이미지에 여러 개의 참조를 갖게 할 수도 있음   docker image tag new-tag pocj8ur4in/vw-api:latest   사설 도커 레지스트리 (Private Docker Registry) : 로컬에 전용 레지스트리를 설치 및 운영  ","categories": [],
        "tags": ["Docker"],
        "url": "/docker3/",
        "teaser": null
      },{
        "title": "[Docker] 4. Docker File",
        "excerpt":"도커 파일 (Dockerfile) : 서버 운영 기록을 코드로 저장한 파일을 특정 시점의 도커 이미지로 빌드           눈송이 서버 (Snowflakes Server) : 각 서버마다 운영 기록이 달라 서로 모양이 다른 서버들이 공존하는 상황       … 서버 간의 운영체제, 컴파일러, 설치된 패키지 등의 차이로 발생하는 문제 개선을 위해 서버 운영 기록을 저장하자!    도커 파일을 생성하는 과정은 테스트 주도 개발의 순환에 부합하다고 볼 수 있다.     테스트 주도 개발 (Test Driven Development) : 선 테스트 후 개발 사이클을 반복하는 개발 방법론       테스트를 작성한다. → 도커 파일을 만든다.   테스트에 실패하고 코드를 수정한다. → 도커 이미지의 빌드에 실패하고 도커 파일을 수정한다.   테스트에 성공한다면, 코드를 리펙터링한다. → 도커 이미지의 빌드에 성공한다면, 도커 파일의 내용을 리펙터링한다.   처음으로 되돌아간다.    DSL (Domain-Specific Language) : 도커 파일을 작성할 때 쓰는 언어 (도커 이미지의 생성 과정 표현)     생성 과정을 표현? : 도커 파일은 일련의 인스트럭션을 실행된 결과로 도커 이미지를 생성한다.         도커 파일의 인스트럭션과 이미지 레이어는 1:1의 관계를 가진다.                FROM : 다른 컨테이너 이미지를 빌드의 시작점으로 지정             AS: 컨테이너에 이름을 붙일 수 있음                ENV : 컨테이너 내에서 사용될 환경 변수를 지정            WORKDIR : 컨테이너 이미지의 파일 시스템에 디렉터리를 만들고, 해당 디렉터리를 작업 디렉터리로 지정            COPY : 로컬의 파일 시스템 내 파일, 디렉터리를 컨테이너 이미지로 복사             --from= : 해당 파일이 호스트 컴퓨터가 아닌 다른 컨테이너의 파일임을 알려줌                CMD : 도커가 이미지로부터 컨테이너를 실행했을 때 실행할 명령을 지정            RUN : 빌드 과정에서 컨테이너 안에서 명령을 실행한 다음에 그 결과를 이미지 레이어에 저장       Q. 도커 파일을 쓰는 이유?   A1. 동일한 환경에서 어플리케이션을 실행 가능하게 한다.     모든 빌드 과정은 도커 컨테이너 내부에서 이루어지며, 각 컨테이너는 모든 도구를 정확한 버전으로 갖추고 있다.            신규 개발자의 적응 기간, 빌드 서버의 관리 부담, 개발자 간의 도구 버전의 차이로 인한 빌드 실패를 줄일 수 있다.           A2. 멀티 스테이지 환경에서 각 단계는 자신만의 캐시를 가져 성능을 향상시킬 수 있다.     도커는 빌드 중에 각 인스트럭션에 해당하는 레이어 캐시를 찾는다.            만약 해당되는 캐시를 찾지 못하면 남은 인스트럭션이 모두 실행되지만, 그 범위가 해당하는 단계 안으로 국한된다.       이어지는 다음 단계는 캐시를 재사용하면서 시작되므로, 캐시 재사용을 통해 빌드 단계에서 시간 절약이 가능하다.           A3. 멀티 스테이지 스크립트를 통해 최종 산출물의 크기를 가능한 한 작게 유지할 수 있다.     최종 산출물인 도커 이미지에 불필요한 도구를 제외하여 어플리케이션의 의존 모듈 자체를 줄일 수 있다.  ","categories": [],
        "tags": ["Docker"],
        "url": "/docker4/",
        "teaser": null
      },{
        "title": "[JPA] 1. JPA",
        "excerpt":"개발자가 SQL을 직접 다룰 때의 문제           DB는 객체 구조와는 다른 데이터 중심의 구조를 가져 객체를 DB에서 직접 저장하거나 조회할 수 없음             개발자가 객체지향 어플리케이션과 DB 중간에서 SQL과 JDBC API를 이용해 변환해야 함       객체를 DB에 CRUD하기 위해서 너무 많은 SQL과 JDBC API를 코드로 작성해야 함                DAO를 이용해 SQL를 은닉해도 결국엔 SQL에 의존적인 개발이 될 수 밖에 없음             개발자가 엔티티를 신뢰하고 사용할 수 없음… 이게 진정한 계층 분할?              그럼, JPA는 어떻게 문제를 해결하였는가?          객체를 DB에 저장하고 관리할 때 JPA가 제공하는 API 사용                저장 → persist() : 객체를 DB에 저장하면, INSERT SQL를 생성해서 DB에 전달         조회 → find() : 객체 하나를 DB에서 조회하면, SELECT SQL를 생성해서 DB에 전달         수정 → 객체를 조회해 값을 변경하면, 트랜잭션을 커밋할 때 UPDATE SQL를 생성해 DB에 전달         연관 객체 조회 → 연관된 객체를 사용하는 시점에 SELECT SQL를 실행                  객체와 관계형 데이터베이스의 패러다임 불일치     객체지향 프로그래밍 : 추상화, 캡슙화, 정보은닉, 상속, 다형성 등 시스템의 복잡성을 제어할 수 있는 다양한 장치 제공   비즈니스 요구사항을 정의한 도메인 모델 또한 객체로 모델링 → 객체와 관계형 데이터베이스는 지향하는 바가 다르다!           상속 : 객체는 상속이라는 기능을 가지지만, 테이블은 상속이라는 기능이 없음             데이터베이스 모델링의 슈퍼타입-서브타입 관계를 이용한다고 해도, 매번 2가지 SQL를 만들어야 함                연관관계 : 객체는 참조를 사용해 다른 객체와 연관관계를 가지고 참조에 접근해서 조회             그러나 테이블은 외래 키를 사용해서 다른 테이블과 연관관계를 가지고 조인을 이용해서 연관된 테이블을 조회       그럼 객체를 테이블에 맞추어 모델링하면? : 외래 키와 참조의 예 → 객체지향의 장점을 잃어버릴 수 있다!                객체 그래프 탐색 : 객체에서 회원이 소속된 팀을 조회할 때에는 참조를 사용해 연관된 팀을 탐색             그런데 참조를 통해 팀을 탐색할 수 있을지 없을지 알 수 없음 → 너무나 큰 제약사항                    결국 DAO를 통해 SQL을 직접 확인하기 위해 상황에 따른 여러 메소드를 만들어야 함                                비교 : 데이터베이스는 기본 키의 값으로 각 row를 구분하지만, 객체는 동일성 비교, 동등성 비교를 활용             동일성 비교 (==) : 객체 인스턴스의 주소 값을 비교, 동등성 비교 (equals()) : 객체 내부의 값을 비교                    기본 키 값이 같은 객체를 2번 조회했을 때, 이 객체들이 다른 인스턴스면 동등하되 동일하지 않다.                              그럼, JPA는 어떻게 문제를 해결하였는가?          상속 → 자바 컬렉션에 객체를 저장하듯이 JPA에 객채를 저장하면 이를 두 테이블에 나눠 저장     연관관계 → 개발자가 관계를 설정해 객체를 저장하면, 참조를 외래 키로 변환해 INSERT SQL 전달     객체 그래프 탐색 : 실제 객체를 사용하는 시점까지 DB 조회를 미루는 지연 로딩 이용     비교 : 같은 트랜잭션일 때 같은 객체가 조회되는 것을 보장      JPA (Java Persistence API) : 자바 진영의 ORM 기술 표준     ORM (Object-Relational Mapping) : 객체와 관계형 DB를 매핑   왜 JPA를 사용해야 하는가?     생산성 : 반복되는 CRUD용 SQL 코드를 작성하는 대신, 자바 컬렉션에 객체를 저장하듯 JPA에 객체를 전달하면 됨   유지보수 : 매번 SQL과 JDBC API 코드를 변경할 필요 없음   패러다임의 불일치 해결 : ORM 프레임워크가 상속, 연관관계, 객체 그래프 탐색, 비교 등의 문제를 대신 해결   성능 : 어플리케이션과 DB 사이에서 동작하면서 다양한 성능 최적화 기회를 제공   데이터 접근 추상화 및 벤더 독립성 : DB 접근 계층을 제공해서 특정 DB 기술에 종속되지 않음      References          자바 ORM 표준 JPA 프로그래밍     ","categories": [],
        "tags": ["JPA"],
        "url": "/jpa1/",
        "teaser": null
      },{
        "title": "[MicroService] 1. MicroService",
        "excerpt":"비즈니스 민첩성 : 자신의 특화된 서비스를 빠르게 제공하고, 피드백을 반영해 서비스를 빠르게 개선      빠른 배포 주기 : 비즈니스 민첩성을 간접적으로 보여주는 지표 → 어떻게 빠른 비즈니스 속도를 가질 수 있을까?   클라우드 인프라 (Cloud Infra)의 등장 : 아마존의 AWS, 구글의 구글 클라우드 플랫폼     비용 측면 : 클라우드의 사용량에 따라 비용을 유연하게 조정할 수 있음 → 사용한 만큼만 비용을 지불   어플리케이션 측면 : 어플리케이션을 여러 개의 블록처럼 관리해 효율성을 극대화            사용량 증가에 따른 성능 및 가용성을 Scale-up, Scale-out → 특정 부분만 탄력성 있게 확장 가능           어떤 서비스가 클라우드 인프라에 적합할까 : 클라우드 프랜들리? 클라우드 네이티브?     클라우드 프렌들리 (Cloud Friendly) : 시스템을 하나의 큰 덩어리로 만들어 클라우드 인프라에 올리는 것   클라우드 네이티브 (Cloud Native) : 시스템을 여러 개의 블록 단위로 나누어 클라우드 인프라에 올리는 것   마이크로서비스 (MicroService) : 여러 서비스 인스턴스가 하나의 비즈니스 어플리케이션 구성     서비스가 갖는 저장소가 각각 다르므로 업무 단위로 모듈 경계가 명확하게 구분            확장하거나 변경할 때에는 특정 기능별로 독립적으로 작업한 뒤에 빌드해서 배포하면 됨       각 서비스가 독립적이기에 서로 다른 언어, 데이터, 기술로도 개발 가능 → 폴리글랏 (Polyglot)              마이크로서비스 이전에는? : 모노리스 (Monolith)         전체 시스템이 하나의 단위로 개발되는 일체식 어플리케이션     일반적으로 클라이언트, 어플리케이션, 데이터베이스의 3-tier 시스템으로 구성     아무리 작은 변화에도 새로운 버전으로 전체를 빌드해서 배포해야 함     단일 프로세스에서 실행되므로, 확장이 필요할 경우에 전체 어플리케이션을 동시에 확장해야 함                로드밸런서를 앞에 두고 여러 인스턴스 위에 큰 덩어리를 복제해 스케일 아웃                  마이크로서비스를 위한 조건은 무엇인가?           업무 기능 중심 팀             콘웨이 법칙 (Conway’s law) : 시스템을 개발할 때 항상 시스템의 모양이 팀 의사소통 구조를 반영                    마이크로서비스를 만드는 팀은 역할이나 기술이 아닌, 업무 기능을 중심으로 한 팀이 되어야 함                       기획자, 디자이너, 프론트엔드 개발자, 백엔드 개발자, 테스터 등 다양한 역할의 인원으로 구성                    서비스를 처음부터 끝까지 만들기 위한 모든 단계의 역할을 갖추고 있음           같은 공간, 같은 시간을 공유하기에 의사소통이 원활하고 빠르게 진행할 수 있음           여러 기능들이 모여 있다는 의미에서 다기능 팀 (Cross-Functional Team)이라고도 부름                                자율적인 분권 거버넌스             각 마이크로서비스 팀은 빠르게 서비스를 만드는 것을 최우선 목적으로 함                    중앙의 강력한 표준이나 절차 준수를 강요받지 않음           스스로 효율적인 방법론과 도구, 기술을 찾아 적용 → 폴리글랏 프로그래밍, 폴리글랏 저장소                                제품 중심의 생명 주기             개발 모델이 프로젝트 단위가 아니라 제품 단위로 구성됨 → 개발 조직과 운영 조직이 결합       소프트웨어를 완성해야 할 기능들의 집합이 아닌, 비즈니스를 제공하는 제품 (Product)로 봄                    우선 빠르게 개발한 뒤에 반응을 보고 개선하는 방식으로 개발           프로젝트 형태의 워터풀 (WaterFall) 개발 방식이 아닌, 제품 중심의 에자일 (Agile) 개발 방식 채용           2~3주 단위의 스프린트 (Sprint)를 통해 소프트웨어에 피드백을 즉각적으로 반영                                CI/CD 파이프라인의 자동화             개발과 운영을 동시에 수행하는 데비옵스 (DevOps)를 궁극적으로 가능하게 함       각각의 CI/CD 파이프라인 프로세스는 CI/CD 파이프라인 도구를 통해 자동화가 이루어짐                    ‘Infrastructure as Code’ : 코드를 이용해 인프라 구성부터 어플리케이션 빌드 및 배포를 정의                                분권 데이터 관리             폴리글랏 저장소 (Polyglot Persistence) 접근법 : 서비스별로 데이터베이스를 갖도록 설계                    각각의 저장소가 서비스별로 분산되어 있으며, 다른 서비스에 API를 통해 접근함                       결과적 일관성 (Eventual Consistency) : 일시적으로 다른 두 서비스의 데이터가 결국엔 동일해짐                    여러 트랜잭션을 하나로 묶지 않고, 별도의 로컬 트랙잭션을 수행           각 저장소 내 데이터의 비즈니스 정합성을 위해 데이터 일관성이 다른 부분을 보상 트랙잭션으로 맞춤                                내결함성을 고려한 설계             내결함성 (Fault Tolerance) : 시스템은 언제든 실패할 수 있는 가능성이 존재한다.                    시스템이 실패해서 더는 진행할 수 없을 때에도, 자연스럽게 대응할 수 있도록 설계하여야 함                       다양한 실패에 대비해 완벽히 테스트할 수 있는 환경을 마련해야 함       시스템의 실패를 감지하고 대응하기 위한 실시간 모니터링 체계 또한 갖춰야 함       장애를 일부러 발생시키는 카오스 몽키 (Chaos Monkey)를 만들어 아키텍처 동작을 점검하기도 함              Reference          도메인 주도 설계로 시작하는 마이크로서비스 개발     ","categories": [],
        "tags": ["MicroService"],
        "url": "/microservice1/",
        "teaser": null
      },{
        "title": "[MicroService] 2. MSA",
        "excerpt":"마이크로서비스 아키텍처 (MSA) : 마이크로서비스를 접목한 아키텍처 구조      클라우드 인프라와 접목해 아마존, 넷플릭스에 의해 구체화 → 비즈니스 성공 사례   각 서비스는 개별 프로세스에서 실행되며, HTTP API를 통해 통신   각 서비스는 비즈니스 기능 단위로 구성되고, 자동화된 배포 방식을 이용해 독립적으로 배포      마이크로서비스 아키텍처 (MSA)와 서비스 지향 아키텍처 (SOA)의 비교         SOA : 컴포넌트를 모아 비즈니스적으로 의미있고 완결적인 서비스 단위로 모듈화                SOA와 MSA의 공통점 : 비즈니스 서비스의 집합으로 시스템을 개발         SOA와 MSA의 차이점 : 이론적인 SOA와 달리, MSA는 클라우드 인프라와 접목해 구체화                     MSA 내부 아키텍처 : API, 비즈니스 로직, 이벤트 발행, 데이터 처리의 구조화 등 MSA 내부 구조를 정의한 것   MSA 외부 아키텍처 : 인프라, 플랫폼, 어플리케이션 영역에 있는 구성 요소 및 그것들의 관계를 정의하는 것   리액티브 선언 (The Reactive Manifesto) : 어플리케이션이 요청에 즉각 응답하고 가동되길 기대     응답성 (Responsive) : 사용자에게 신뢰성 있는 응답을 빠르고 적절히 제공하는 능력   탄력성 (Resilient) : 장애가 발생하더라도 시스템 전체에 영향을 주지 않고 복구하는 능력   유연성 (Elastic) : 사용량에 변화가 있더라도 그에 비례해 자원을 조절해 균일한 응답성을 제공하는 능력   메시지 기반 (Message Driven) : 비동기 메시지로 위치 투명성, 느슨한 결합, 논블로킹 통신을 지향   → 4가지 요건을 만족하는 시스템을, 급변하는 상황을 적응할 수 있는 리엑티브 시스템 (Reactive System)이라 정의   강결합에서 약결합의 아키텍처로의 변화     소프트웨어 아키텍처 : 소프트웨어를 구성하는 요소와 그 구성 요소 간의 관계를 정의한 것            아키텍처를 정의하는 과정 : 시스템 구축을 위한 여러 비기능 요건들을 만족하는 해결 방법을 찾는 과정                    비기능 요건 : 시스템 성능, 시스템 가용성, 보안, 유지보수성, 확장성 등                       마이크로서비스 아키텍처는 ‘클라우드’라는 가상화된 인프라를 활용한 것이므로, 이를 고려해 설계해야 함           아키텍처 유연성 (Architecture Flexibility) : 시스템 자체가 변화 및 확장에 언제든지 대응할 수 있는 능력            시스템을 구성하는 구성 요소 간의 관계들이 느슨하게 결합되어 언제든지 대체되거나 확장될 수 있음       리액티브 시스템이 리액티브하기 위해서 반드시 갖춰야 할 특성 중 하나       클라우드 인프라 자체가 유연성과 확장성을 갖추므로, 어플리케이션 아키텍처 또한 아키텍처 유연성이 필요                과거 : 아키텍처 구성 요소들이 특정 벤더의 제품에 전적으로 의존            유명한 제품군을 사용함으로 품질이 보장될 수 있음       특정 기술에 락인 (lock-in)되어 시스템을 쉽게 변경하거나 확장하기 어려움           현재 : 클라우드 환경 아래에서 사용하는 오픈 소스 기반 제품들이 충분한 기능, 품질, 호환성을 제공            아키텍처 설계가 필요한 레이어에서 적절한 솔루션을 선택하고 이를 조합하는 개방적 방식으로 변화       클라우드 기반 어플리케이션의 구축에 필요한 인프라 및 어플리케이션 영역에 다양한 제품들이 등장           MSA 패턴 : MSA의 문제 영역에 대해 여러 사람들에 의해 검증되어 정리된 스타일 혹은 패턴     인프라 구성 요소 : 마이크로서비스를 지탱하는 인프라스트럭처를 구축하는 데에 필요한 구성 요소   플랫폼 패턴 : 인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패턴   어플리케이션 패턴 : 마이크로서비스 어플리케이션을 구성하는 데에 필요한 패턴   인프라 구성 요소를 서비스 유형별로 나누어 해당되는 제품 중 하나를 의사결정 → 클라우드 인프라     IaaS (Infrastructure as a Service) : 가상 머신, 스트리지, 네트워크 등 인프라 제공            고객이 관리할 수 있는 범위가 가장 넓은 클라우드 컴퓨팅 서비스       AWS 등 퍼플릭 클라우드 공급 업체 (CSP)가 준비한 환경을 고객이 선택할 수 있음       가상화된 물리적 자원을 UI 형태의 대시보드 혹은 API 형태로 제공       고객은 서버와 스트리지에 접근할 수 있지만, 클라우드 내 가상 데이터 센터를 통해 리소스를 전달받는 형태       개발자는 운영체제와 어플리케이션을 직접 관리해야 함 : 개발자와 인프라 관리자의 역할이 분담       예시 : AWS EC2, AWS S3           CaaS (Container as a Service) : 업로드, 구성, 실행, 확장, 중지할 수 있는 컨테이너 제공            가상 머신이 아닌 컨테이너를 기본 리소스로 활용해 어플리케이션을 개발, 실행, 관리       컨테이너화된 어플리케이션을 빌드하고 배포하는 개발 환경은 퍼플릭 클라우드 공급 업체 (CSP)가 제공       예시 : Kubernetes Service, AWS ECS           PaaS (Platform as a Service) : 어플리케이션에 미들웨어, 런타임까지 탑재한 플랫폼을 제공            가상화된 클라우드 위에 원하는 서비스를 개발할 수 있도록 개발 환경을 미리 구축해 서비스 형태로 제공       고객은 개발 환경을 고려할 필요 없이 어플리케이션 자체에 집중할 수 있음       어플리케이션이 플랫폼에 종속되어 개발되므로, 다른 플랫폼으로의 이식이 어려울 수도 있음       예시 : Lambda, AWS Elastic Beanstalk           시스템의 기반이 되는 인프라 레이어의 구축 → 베어메탈 장비 혹은 가상 인프라 환경을 통한 구축     가상 인프라 환경 : 하이퍼바이저 (Hypervisor)의 사용 여부 및 게스트 OS 유무에 따라 나뉨            가상 머신 (Virtual Machine) : 하이퍼바이저를 통해 하나의 시스템에서 여러 운영체제를 사용                    운영체제 패치 및 관련 라이브러리 설치로 인한 오버헤드가 지속적으로 발생                       컨테이너 (Container) : 컨테이너 엔진을 사용해 가상의 격리된 공간을 생성                    도커 (Docker) : 필요 라이브러리나 실행 파일을 여러 레이어 이미지로 제어                            이식성 : 도커만 실행할 수 있으면 호스트 커널에 상관없이 동일하게 사용               신속성 : 크기가 작고 가벼워 빠른 배포가 가능 + 문제 발생 시 다시 가동하면 됨               재사용성 : 동일한 환경을 재사용해 쉽게 설정 가능 → 서버 환경 구축이 쉬워짐                                               컨테이너 오케스트레이션 (Container Orchestration) : 컨테이너 관리 기술                    컨테이너 배치 및 복제, 확장 및 축소, 장애 복구 컨테이너 간 통신, 로드밸런싱 등           쿠버네티스 (Kubernetes) : Pod, Deployment, Replica Sets 정보 확인 가능                            각 컨테이너가 요구하는 자원을 쿠버네티스에 요청하면 노드에 맞춰 자동 배치               컨테이너 이상을 점검해, 실패하면 컨테이너를 자동으로 교체하고 리스케줄링               일정량의 CPU 및 메모리 사용량을 초과하면 자동으로 수평 확장                                                   마이크로서비스의 운영과 관리를 지원할 클라우드 플랫폼 (미들웨어)의 구축 → 플랫폼 패턴     데비옵스 (DevOps) : 개발과 운영이 분리되지 않은 개발 및 운영을 병행할 수 있는 조직 또는 문화            소프트웨어를 빠르게 개발하게끔 지원하는 빌드, 테스트, 배포를 위한 자동화 환경       지속적 제공 (CI) : 빌드된 소스 코드의 실행 파일을 실행 환경에 반영하기 전에 진행       지속적 배포 (CD) : 저장소에 빌드한 소스 코드의 실행 파일을 실행 환경까지 자동으로 배포              자동 빌드 및 배포 절차         매일 자신이 작성한 소스 코드와 이를 테스트할 테스트 코드를 형상관리 시스템에 보낸다. (Push)     매일 빌드 도구에서 형상관리 서버의 코드를 가져와 (Pull) 통합하고, 자동으로 빌드하고 테스트를 수행한다.     테스트 수행 결과를 리포트에 기록하고, 빌드된 소스 코드를 스테이징 환경에 자동으로 배포한다.     테스터가 스테이징 환경에서 테스트를 수행할 때 혹은 리포트 결과에 문제가 있으면, 소스 코드를 수정한다.         빌드·배포 파이프라인의 설계 : 빌드·배포 과정동안 수행해야 할 업무 (task)를 정의한 것            리포지토리에서 소스 코드를 가져와 빌드해 실행 파일을 만드는 작업       이전 작업이 성공하면, 다음 작업이 자동으로 수행히게끔 위의 작업들을 관리하는 작업       실행할 어플리케이션을 실행 환경에 배포하는 작업           → IaaS를 통해 빌드·배포 파이프라인의 절차를 완벽하게 자동화할 수 있음          Reference          도메인 주도 설계로 시작하는 마이크로서비스 개발     ","categories": [],
        "tags": ["MicroService"],
        "url": "/microservice2/",
        "teaser": null
      },{
        "title": "[vocawik] vocawik 프로젝트 소개",
        "excerpt":"0. 들어가며   음성 합성 (Speech Synthesis)은 인간의 육성 혹은 그와 비슷한 주파수를 합성하여 인공적인 음성을 자동으로 만들 수 있는 기술을 말한다. 인간의 말소리 혹은 이와 유사한 소리를 일정한 단위로 분할해 각 조각에 부호를 붙이는 방식으로 데이터화해 음성 라이브러리 (Vocal Library)에 저장하면, 음성 합성 엔진 (Speech Synthesis Engine)이 사용자의 지시에 따라 음성 라이브러리에 필요한 음성 단위를 불러오고 이를 기반으로 하여 인공적인 음성을 합성한다. 음성 합성 기술 문자를 대신 읽어주는 스크린 리더 (Screen Reader)로서, 1984년 애플 매킨토시 (Apple Macintosh)에 매킨토크 (MacInTalk) 기능으로 탑재된 이후 오랜 기간에 걸쳐 다양한 분야에서 활용되고 있다.    2003년 2월 야마하 (Yamaha)에서 개발된 보컬로이드 (VOCALOID) 엔진 역시 음성 합성을 기반으로 한 소프트웨어로, 사용자가 프로그램만으로 사람의 노랫소리를 활용한 음원을 작곡하는 것을 목표로 한다. 그러나 기존 음성 합성 기술이 산업적인 용도에 초점을 맞춰져 있던 것과 달리, 보컬로이드를 비롯한 음성 합성 엔진은 음성 데이터에 다이폰 (Diphone), 음성의 강약, 비브라토, 숨소리 등의 부가적인 정보들을 더한 가수 라이브러리 (Singer Library)를 제공해 인간의 음성에 흡사한 소리를 생성할 수 있다. 또한 스코어 에디터 (Score Editor)는 노래의 가사나 음표만이 아닌, 음원의 억양와 높낮이 등을 가변하여 사용자가 자유롭게 음원을 조절할 수 있게끔 한다.         야마하가 보컬로이드를 발표한 이후, 여러 기업들이 음성 제공자 (Voice Provider)의 목소리를 활용한 가수 라이브러리를 발표하였다. 2007년 8월 31일 크립톤 퓨처 미디어 (Crypton Future Media)에서 발매한 하츠네 미쿠 (初音ミク)는 대표적인 음성 합성 이미지 캐릭터로, 현대 일본 캐릭터 문화의 상징 중 하나로 여겨질 만큼 어마어마한 성공을 거두었다. 최근까지도 Project SEKAI COLORFUL STAGE! feat. 初音ミク, ポケモン feat. 初音ミク Project VOLTAGE 18 Types/Songs와 같은 관련 컨텐츠나 피규어, 넨도로이드 등 굿즈들이 끊임없이 나오고 있으며, SONY, TOYOTA 등 유명 회사들과의 콜라보 역시 지속적으로 이루어지고 있다.   음성 합성 소프트웨어를 활용한 음악 산업의 성공에는 관련 창작물들을 하나의 ‘창작 문화’로 여기면서 자발적으로 생산·유통·소비 활동에 참여하는 팬덤의 영향력이 뒷받침되었다고 본다. 아마추어 작곡가들이 가수나 밴드를 통해 자신이 작곡한 곡을 재상산하는 것은 현실적인 어려움이 존재한다. 그러나 음성 합성 소프트웨어를 통해 손쉽게 자신의 곡에 가수의 음성을 넣는 것이 가능해지면서, 음성 합성 소프트웨어를 활용한 자신의 곡을 투고하는 프로듀서 (Producer)들이 등장하였다. 그리고 유튜브 (Youtube), 니코니코 동화 (ニコニコ動画)와 같이 사용자가 동영상을 자유롭게 올리거나 시청할 수 있는 비디오 플랫폼을 통해 생산자와 소비자가 시공간의 제약을 넘어 자유롭게 교류할 수 있는 환경 또한 조성되었다. 거기에 더해 소비자가 단순히 컨텐츠를 즐기는 것을 넘어, 직접 프로듀서로 활동하거나 일러스트, MMD와 같은 2차 창작물을 생산하는 활동을 하면서 문화적 파급력을 갖게 되었다고 볼 수 있다.         국내에서도 이런 음성 합성 소프트웨어를 활용한 음악 산업의 성공과 파급력에 주목하여, 한국어를 지원하는 보컬로이드 가수 라이브러리인 시유 (SeeU)나 유니 (UNI)가 출시되었고, 크리크루 (CreCrew)나 보카로 가사 위키 등 음성 합성 소프트웨어 관련 웹 사이트 또한 개설된 바가 있다. 그러나 음성 합성 소프트웨어가 일본이나 전세계에 미친 영향력에 비하면 국내에서의 파급력은 매우 제한적이었으며, 특히 관련 웹 사이트의 경우에는 운영되었던 사이트들이 폐쇄되면서 이용자들에게 불편함을 겪거나 수년간 축적된 데이터가 소실되는 경우가 발생하곤 하였다. 그래서 음성 합성 소프트웨어를 주제로 한 지속 가능한 웹 사이트의 구현을 목표로 하여 ① 국내외에서 운영되었거나 운영 중인 음성 합성과 관련된 웹 사이트의 운영 사례를 분석해보고, ② 분석한 결과를 반영해 웹 사이트를 설계하고자 한다.   1. 사이트 운영 사례   전세계적으로 많은 음원 합성 엔진를 다루는 사이트들이 개설되어 현재까지 운영 중이므로, 먼저 사례로 선정된 사이트들의 기준에 대해 언급하고자 한다. ① 음성 합성 소프트웨어에 관심이 많은 사용자들이 존재하면서, ② 음성 합성 소프트웨어와 관련된 창작 활동이 활발하게 이루어지거나, ③ 사이트에 도입할 만한 독창적인 컨텐츠가 존재하는지를 고려하였다. 다음은 사이트를 제외할 때 참고한 기준이다.      VOCALOID™나 CeVIO처럼 음성 합성 엔진이나 가수 라이브러리를 개발한 회사들이 운영하는 공식 사이트를 제외하였다. 단, 피아프로 (piapro)처럼 음성 합성 엔진이나 가수 라이브러리를 개발한 회사들이 설립하였더라도, 자사의 제품을 홍보하는 것이 주 목적이 아닌 사이트는 포함하였다.   나무위키, 위키백과, 니코니코 대백과 (ニコニコ大百科)처럼 음성 합성 소프트웨어만이 아닌 다양한 주제를 다루는 위키 (wiki)를 제외하였다. 물론 선정된 사이트 중에 여러 위키들이 존재하므로, 필요한 경우에 직간접적으로 언급할 것이다.   동영상 공유 사이트나 컨텐츠 창작 사이트의 경우 음성 합성 소프트웨어와 관련된 창작 활동이 활발하게 이루어진 사이트들을 선정하되, 보컬로이드 제국처럼 소셜 네트워크 플랫폼이나 커뮤니티 사이트 내에 음성 관련 엔진과 관련된 주제로 한 카페나 블로그, 게시판 등의 형태로 존재하는 경우는 제외하였다.   미쿠린넷처럼 웹 사이트가 폐쇄된 지 오래되어, 사이트에 관한 자료가 거의 존재하지 않는 경우를 제외하였다.   (1) 니코니코 동화 (ニコニコ動画)   니코니코 동화는 2006년에 개설된 일본의 동영상 공유 사이트이다. 사용자들이 영상을 감상하면서 코멘트를 남기면 해당 시간대에 그 영상 위로 코멘트가 실시간으로 지나가는 ‘리얼타임 코멘트’ 시스템이 유명한데, 생방송이 아닌 동영상을 시청하더라도 다른 이용자들의 코멘트를 보면서 현장감을 느낄 수 있는 것이 장점이다. 이 시스템으로 니코니코 동화는 타 사이트와 차별화되는 자신만의 문화를 만들었다고 봐도 무방한데, 특정 장면에서 사용자들의 코멘트가 화면을 가득 채우는 ‘탄막’이나 코멘트를 이용하여 그림을 만들어내는 ‘코멘트 아트’ 등이 있다. 이런 니코니코 동화 특유의 문화에 보컬로이드를 위시한 여러 서브컬쳐 팬덤의 호응이 한데 어우려지면서, 한때 일본 내 웹 사이트 시장의 대부분을 잠식한 시기도 있었다. 니코니코 동화에서 10만/100만/1000만 재생 수를 달성한 영상들에 붙는 태그인 전당입성(殿堂入り)/전설입성(伝説入り)/신화입성(神話入り)이나, 음성 합성 소프트웨어 관련 랭킹을 매주 집계하는 주간 VOCAL Character 랭킹 (週刊VOCAL Characterランキング)이 여전히 보편적인 지표로 여겨지는 이유이다.  현재 니코니코 동화는 노후화된 시스템와 정체된 컨텐츠로 인해 현재는 일본 내에서 유튜브나 틱톡에 완전히 밀려버린 상태이나, 창작자 친화 플랫폼으로의 입지를 구축하면서 어느 정도 차별화에 성공했다고 여겨진다. 2020년부터 진행중인 The VOCALOID Collection가 대표적인 예시인데, 행사 기간동안 투고된 작품들에 한하여 집계되는 랭킹 상위에 입상할 경우 크리에이터 지원금을 지급하거나 리듬 게임에 곡이 수록되는 혜택 등을 통해 창작자들의 참여를 도모하고 있다. 또한 재생 수나, 코멘트 수, 좋아요 수 등 데이터에 빌보드 재팬에서 개발한 계수를 곱해 음성 합성 소프트웨어를 사용한 악곡의 인기를 측정하는 차트인 니코니코 VOCALOID SONGS TOP20 (ニコニコ VOCALOID SONGS TOP20)으로 다년간 축적된 웹 사이트 내의 데이터를 적극적으로 활용하는 행보 또한 보이고 있다.   (2) 유튜브 (Youtube)   유튜브는 2005년에 개설된 미국의 동영상 공유 사이트이다. 2017년 이후 니코니코 동화가 침체되면서, 대다수의 프로듀서들이 니코니코 동화만이 아닌 유튜브에도 음성 합성 소프트웨어 관련 창작물을 업로드하게 되었다. 이렇게 사용자들이 전세계적으로 분포한 유튜브에 창작물들이 업로드되면서, 해외에서 음성 합성 소프트웨어에 대해 접할 기회가 늘어나게 되었고 자연스레 해외 팬덤의 영향력 또한 커지게 되었다.   (3) 비리비리 (哔哩哔哩)   비리비리는 2010년에 개설된 중국의 동영상 공유 사이트이다.   (4) 피아프로 (piapro)   피아프로는 2007년에 개설된 일본의 컨텐츠 창작 사이트이다.   (5) 크리크루 (CreCrew)   (6) 아트리 (ateli)   (7) VOCALOID Amino   (8) VocaVerse Network   (9) VNN   (10) Songrium   (11) Iwara   (12) 보카로 가사 위키   (13) 보컬로이드 위키 (VOCALOID Wiki)   (14) 하츠네 미쿠 위키 (初音ミク Wiki)   (15) VocaDB   (16) MikuDB   (17) Vocaloard Chart   (18) COLORTO   (19) 보카로 DB (ボカロDB)   (20) Kiite Radar   (21) VOCALENDAR   2. vocawik 설계   (1) 고려 사항           명확한 도메인 정의          참고문헌          논문                김도희. (2018). 보컬로이드 가상캐릭터의 특성 분석 연구. 일러스트레이션 포럼.         임현정. (2012). 보컬로이드 2차 창작의 변형구조 연구. 이화여자대학교 대학원 석사학위논문.                 기사                안태춘, ‘한국 보컬로이드는 어떻게 나아가야할까?’                 도서                남경호, 사례로 배우는 언어 전환 프로젝트 관리                 ","categories": [],
        "tags": ["vocawik"],
        "url": "/vocawik1/",
        "teaser": null
      },{
        "title": "[TIL] 2024년 01월 TIL",
        "excerpt":"2024년에는 TIL를 작성하자!   2023년은 내게 있어 다사다난한 해였다. 교수님 밑에서 친구들과 함께 프로젝트도 해보고, 기업에 취업하고자 여러 군데에 서류도 넣어 면접까지 진행하였다. 그리고 내가 부족하다고 느낀 부분을 메꾸기 위해 여러 도서들을 사서 정리하기도 하였으며, 주니어 개발자를 위한 여러 행사들 또한 참여하였다. 그런데 지금 올해를 회고하는 내게 있어서 아쉬운 점은 내가 경험한 것들, 내가 공부한 것들, 내가 작업한 것들을 성실히 기록하지 않았다는 점이다. 그래서 이제 하루 앞으로 다가온 2024년에는, 내가 매일매일 성장한 기록을 글의 형태로 남기고자 한다.    TIL은 Today I Learned의 약자로, 오늘 하루동안 배운 것 혹은 경험하고 느낀 것들을 기록하면서 회고하는 것이다. 이미 여러 개발 블로그들을 보면, 김남윤님의 TIL이나 초보몽키님의 TIL처럼 많이들 TIL을 쓰시는 것을 볼 수 있다. TIL이 정해진 양식이나 규칙 없이 자유롭게 자신의 스타일로 작성하다 보니 보고서처럼 쓰시는 분들도, 일기처럼 쓰시는 분들도 있어 정말 다양하게 쓰신다는 것을 알 수 있었다. 원래는 양식이나 규칙을 확실히 정해놓고 매일매일 쓰려고 하였는데 일단은TIL을 한번도 작성해본 적이 없다보니, 한 일주일 정도는 여러 형태로 글을 써보면서 나한테 적합한 글쓰기 방식을 찾아봐야할 것 같다. 대신에 내가 왜 TIL을 작성해야 하는지에 대해 생각해보았다.           TIL을 쓰는 이유 1. 내가 매일 경험한 것을 회고하기 위해    하루를 보내면서 내가 모르는 내용이나 개념을 만나는 경우가 정말 많다. 그리고 나의 솔루션이 옳은지에 대한 기술적인 고민을 하는 과정 또한 경험하게 된다. 그러나 그동안 내가 경험한 것들을 기록할 때에는, 이런 과정을 생략하고 개조식으로 글을 써서 내가 중요하다고 생각한 부분 위주로 잘 정리하고자 노력하였다. 지금 와서 내가 정리한 글들을 보면 ‘내가 어떤 문제 상황에서 어떻게 해결하였는지?’에 대한 과정이 결여되었다는 느낌을 받았다. 하지만 TIL처럼 매일 내가 경험한 것들을 작성한다면, 나의 문제 해결 과정이 잘 들어난 글쓰기가 되지 않을까 생각하였다.            TIL을 쓰는 이유 2. 나 자신의 노력을 증명하기 위해    기업에서 원하는 주니어 개발자는 어떤 인재일까? 에 대해 고민을 많이 해보았다. 사실 시니어들의 눈에 주니어 개발자 모두가 고만고만한 실력이나 기술 스택을 가진 것처럼 보일 것 같았다. 그렇다면 내가 남들보다 더 낫다고 할 수 있는 부분은 무엇일까? 나는 그것이 성장 가능성이지 않을까 생각하였다. TIL은 내가 성장에 대한 갈망이 높고, 성실함과 꾸준함을 겸비하였음을 어필할 수 있어, 내가 남들보다 더 성장할 수 있는 사람이라는 것을 보여줄 수 있을 것이라고 기대한다.       2024년 01월 01일 (월)      신년을 맞아 앞으로 내가 해야할 일들을 아래와 같이 정리해보는 시간을 가졌다.            Python으로 알고리즘 문제를 풀면서 코딩 테스트 준비하기       Java, Spring과 같이 백엔드 개발자에 있어 필요한 내용을 공부해 포스트로 정리하기       기획부터 배포까지의 일련의 과정을 경험할 수 있는 협업 프로젝트 진행하기       정보처리기사, SQLD와 같이 취업에 도움이 될 수 있는 자격증 취득하기       내가 목표로 하는 회사들에 지원하여 서류, 코딩 테스트, 면접과 같은 채용 프로세스 경험하기       하루동안 내가 경험한 일들을 기록하는 TIL 작성하기       자신의 기술과 역량을 보여줄 수 있는 개발자 포트폴리오 만들기           vocawik 기획서 작성에 참고하기 위해 사례로 배우는 언어 전환 프로젝트 관리 1장의 내용을 정리하였다.   Goodnotes 앱으로 필기하기 위해 알라딘으로 구매한 전자책을 스캔하는 Automator 워크플로우 파일을 작성하였다.   2024년 01월 02일 (화)      어제 작성한 Automator 워크플로우 파일을 오전에 실행해보니 같은 파일명으로 파일을 덮어쓰는 오류가 있었다. 그래서 스크린샷을 찍어 이를 각각 다른 이름으로 저장하고, 필요한 경우에 색상 반전을 실행하는 파이썬 코드를 작성하였다.            사실 저장된 스크린샷 이미지들을 하나의 PDF로 만드는 것까지 코드로 작성하였는데, 막상 실행해보니 출력된 결과물의 화질이 그렇게 좋지 않아 이 부분은 수작업으로 진행하였다.       알라딘으로 구매한 전자책 37권과 재학 기간에 스캔한 전공 서적 6권을 대상으로 진행하였다. 전자책을 스캔하는 작업과 색상 반전을 실행하는 작업 모두 내 예상보다 많은 시간이 소요되서 하루 내내 여기에만 매달린 거 같다.           from PIL import ImageGrab import time import pyautogui   def take_screenshot(filename):     # 로딩 시간 지연     time.sleep(2)      # 현재 화면 전체를 캡처     screenshot = ImageGrab.grab()      # 파일로 저장     screenshot.save(filename)      # 오른쪽 방향키 누르기     pyautogui.press('right')   if __name__ == \"__main__\":     # 초기 시간 지연     time.sleep(5)      for i in range(1, 256):         file_path = \"page\" + str(i) + \".png\"          # 스크린샷 찍기         take_screenshot(file_path)    from PIL import Image   def invert_colors(image_path, output_path):     # 이미지 열기     image = Image.open(image_path)      # 이미지 모드 확인 및 변경 (모드가 'RGBA' 또는 'LA'인 경우에 대비)     if image.mode in ('RGBA', 'LA'):         r, g, b, a = image.split()         rgb_image = Image.merge('RGB', (r, g, b))     else:         rgb_image = image.convert('RGB')      # 이미지 크기 및 모드 확인     width, height = rgb_image.size      # 각 픽셀의 RGB 값을 반전     inverted_image = Image.new('RGB', (width, height))     for x in range(width):         for y in range(height):             pixel = rgb_image.getpixel((x, y))             inverted_pixel = tuple(255 - value for value in pixel)             inverted_image.putpixel((x, y), inverted_pixel)      # 반전된 이미지 저장     inverted_image.save(output_path)   if __name__ == \"__main__\":     for i in range(1, 256):         input_image_path = \"page\" + str(i) + \".png\"         output_image_path = \"pages\" + str(i) + \".png\"         invert_colors(input_image_path, output_image_path)       vocawik 기획서 작성에 참고하기 위해 사례로 배우는 언어 전환 프로젝트 관리 2장의 내용을 정리하였다.   2024년 01월 03일 (수)      오늘 아침, 지난달에 면접을 진행한 디지털하나路 2기 금융서비스개발 분야에 합격하였다는 전화를 받았다.            솔직히 말하면 면접을 진행하면서 아쉬운 점들이 많았고, 경쟁률도 내 예상보다 높은 편이였기에 이렇게 합격을 하게 될 줄은 전혀 몰랐다. 6개월이라는 짧지 않은 기간에 매일 9시간씩 심도 깊게 진행되는 프로그램인 만큼, 본 과정에 열심히 참여하여 이전보다 성장할 수 있도록 노력해야겠다.       공고문에 따르면 디지털하나路 금융서비스개발의 커리큘럼은 금융의 이해, 서비스 개발의 요소, FrontEnd 개발, BackEnd 개발, 데이터베이스와 보안, 3차례의 팀 프로젝트로 구성되어 있다. 과정 하나하나가 BackEnd 개발자를 지망하는 내게 큰 도움이 될 것 같고, 특히 부족한 협업 경험이 아킬레스건이라 생각한 내게 있어 팀 프로젝트를 3차례 진행해보는 것은 굉장한 메리트가 될 수 있을 것이라고 생각한다.       하나은행 HR 담당자 분들이 진행하시는 채용설명회 및 채용상담 또한, 자소서나 포트폴리오를 어떻게 작성하고 관리할지 고민이 많고 실제 면접 경험이 부족한 나에게 큰 도움이 될 것 같다.                 vocawik 기획서 작성에 참고하기 위해 사례로 배우는 언어 전환 프로젝트 관리 3장의 내용을 정리하였다.            디지털하나路 일정을 감안힌다면, 보다 빠른 기획서의 작성이 필요하다. 오는 1월 13일에 인프라 매니저와의 만남을 약속하였고 1월 15일에 디지털하나路 과정이 시작될 예정이니, 1월 11일에 기획서 초안을 완성하도록 한다.           2024년 01월 04일 (목)      내일배움카드 발급이 이렇게 오래 걸릴 줄은 몰랐다. 디지털하나路 일정이 촉박하다보니, 카드를 직접 수령하려고 은행만 세 군데 다녀왔다. 그건 그렇고 그동안 작성한 내용을 읽어보니 점점 일기장이 되는 것 같다? 그래도 일단은 괜찮겠지..?   vocawik 기획서 작성에 참고하기 위해 사례로 배우는 언어 전환 프로젝트 관리 4장의 내용을 정리하였다.   2024년 01월 05일 (금)      vocawik 기획서 작성에 참고하기 위해 사례로 배우는 언어 전환 프로젝트 관리 5장의 내용을 정리하였다.            책의 내용이 7장으로 구성되어 있는데, 7장은 후일담이라 내일 6~7장의 내용을 정리해 마무리하면 될 것 같다.       정리를 마무리한 다음에는 정리된 내용을 토대로 기획서의 뼈대를 잡을 계획이다. 내가 기획하고 있는 프로젝트는 기존 프로젝트의 언어 전환이 아닌 신규 서비스의 구현이긴 하지만, 실제로 어떻게 프로젝트를 관리할지에 대해 다시 한 번 생각해볼 수 있었으며 기획서에도 분명 채용할 만한 부분이 많음을 느끼고 있다.                    기획서는 현재 1. 기획 배경, 2. 타 사이트 분석, 3. 서비스 설계의 흐름으로 작성하고 있으며, 현재 1번의 내용은 완성하고 2번의 내용을 작성하고 있는 상태이다.                          ","categories": [],
        "tags": ["TIL"],
        "url": "/til1/",
        "teaser": null
      }]
